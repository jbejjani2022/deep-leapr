{
  "model_info": {
    "learner": "did3",
    "domain": "text_regression_rm_helpful",
    "model": "gpt-4o-mini",
    "checkpoint_path": "results/models/did3__text_regression_rm_helpful__gpt-4o-mini.pkl",
    "features_path": "results/features/did3__text_regression_rm_helpful__gpt-4o-mini.json",
    "analysis_date": "2025-11-17T11:11:29.258524"
  },
  "dataset_info": {
    "split": "validation",
    "num_samples": 236,
    "feature_matrix_shape": [
      236,
      368
    ]
  },
  "feature_importance": [
    {
      "feature_index": 361,
      "feature_name": "feature_361",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of words longer than 6 characters\"\n    long_words = sum(1 for word in text.split() if len(word) > 6)\n    return float(long_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.1324605989430095,
        "mean_shap": 0.013249315454417182,
        "std_shap": 0.14254349485272919,
        "min_shap": -0.26257280495470037,
        "max_shap": 0.25033496970688507
      },
      "rank": 1
    },
    {
      "feature_index": 59,
      "feature_name": "feature_59",
      "feature_code": "def feature(text: str) -> float:\n    'Count of words longer than 6 characters'\n    long_words = sum(1 for word in text.split() if len(word) > 6)\n    return float(long_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.13227607677615238,
        "mean_shap": 0.01197231130301943,
        "std_shap": 0.1426063171903842,
        "min_shap": -0.269337783674557,
        "max_shap": 0.24480418493201778
      },
      "rank": 2
    },
    {
      "feature_index": 308,
      "feature_name": "feature_308",
      "feature_code": "def feature(text: str) -> float:\n    'Average number of words per paragraph'\n    paragraphs = text.split('\\n')\n    paragraph_lengths = [len(p.split()) for p in paragraphs if p.strip()]\n    return float(statistics.mean(paragraph_lengths)) if paragraph_lengths else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.07981227588704533,
        "mean_shap": 0.014612242308113423,
        "std_shap": 0.0910629433485113,
        "min_shap": -0.19223730728349536,
        "max_shap": 0.22087512426192954
      },
      "rank": 3
    },
    {
      "feature_index": 31,
      "feature_name": "feature_31",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the word 'I' in the text\"\n    word_count = text.lower().split().count('i')\n    total_words = len(text.split())\n    if total_words == 0:\n        return 0.0\n    return float(word_count) / total_words\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.07214502566923717,
        "mean_shap": 0.01412335748658185,
        "std_shap": 0.0829587845754511,
        "min_shap": -0.2014341861584365,
        "max_shap": 0.20072850529377392
      },
      "rank": 4
    },
    {
      "feature_index": 120,
      "feature_name": "feature_120",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of stopwords in the text\"\n    stopwords = set(['a', 'an', 'the', 'is', 'and', 'in', 'to', 'of', 'for', 'on', 'that', 'with'])\n    words = text.lower().split()\n    stopword_count = sum(1 for word in words if word in stopwords)\n    return float(stopword_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.07207722433378017,
        "mean_shap": 0.005810688742350554,
        "std_shap": 0.07388947471087998,
        "min_shap": -0.10951781189910943,
        "max_shap": 0.11767422764308279
      },
      "rank": 5
    },
    {
      "feature_index": 102,
      "feature_name": "feature_102",
      "feature_code": "def feature(text: str) -> float:\n    'Density of nouns in the text based on a simple heuristic'\n    words = text.split()\n    noun_count = sum(1 for word in words if word.lower() in {\n        'i', 'you', 'he', 'she', 'it', 'we', 'they', 'this', 'that', \n        'who', 'what', 'where', 'which', 'whose', 'whoever', 'whomever'})\n    return noun_count / (len(words) + 1)  # prevent division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.06478135979684219,
        "mean_shap": -0.00706376142654156,
        "std_shap": 0.07672600893684732,
        "min_shap": -0.2129936378305706,
        "max_shap": 0.13370381532614503
      },
      "rank": 6
    },
    {
      "feature_index": 323,
      "feature_name": "feature_323",
      "feature_code": "def feature(text: str) -> float:\n    'Density of nouns in the text based on a simple heuristic'\n    words = text.split()\n    noun_count = sum(1 for word in words if word.lower() in {\n        'i', 'you', 'he', 'she', 'it', 'we', 'they', 'this', 'that', \n        'who', 'what', 'where', 'which', 'whose', 'whoever', 'whomever'})\n    return noun_count / (len(words) + 1)  # prevent division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.061336722003880954,
        "mean_shap": -0.007168211488244191,
        "std_shap": 0.07204680261377792,
        "min_shap": -0.18957565302663495,
        "max_shap": 0.13679698162290643
      },
      "rank": 7
    },
    {
      "feature_index": 349,
      "feature_name": "feature_349",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of unique characters in the text\"\n    unique_chars = set(text)\n    return float(len(unique_chars)) / len(text) if len(text) > 0 else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.054459588336159416,
        "mean_shap": -0.00034265448226903733,
        "std_shap": 0.07420867112709942,
        "min_shap": -0.06909371458437627,
        "max_shap": 0.24471312472190487
      },
      "rank": 8
    },
    {
      "feature_index": 61,
      "feature_name": "feature_61",
      "feature_code": "def feature(text: str) -> float:\n    \"Percentage of non-ASCII characters in the text\"\n    non_ascii_count = sum(1 for c in text if ord(c) > 127)\n    return float(non_ascii_count) / len(text) if len(text) > 0 else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.052985463651623786,
        "mean_shap": -0.003940432900205872,
        "std_shap": 0.06684472522721381,
        "min_shap": -0.20782216113873403,
        "max_shap": 0.06845548587371103
      },
      "rank": 9
    },
    {
      "feature_index": 81,
      "feature_name": "feature_81",
      "feature_code": "def feature(text: str) -> float:\n    'Total character count excluding whitespace'\n    return float(len(text.replace(' ', '')))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.04496975637667395,
        "mean_shap": -0.003154795306938716,
        "std_shap": 0.05720028720341637,
        "min_shap": -0.06217246114198145,
        "max_shap": 0.17127212403291883
      },
      "rank": 10
    },
    {
      "feature_index": 44,
      "feature_name": "feature_44",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of sentences that ask questions'\n    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n    question_count = sum(1 for s in sentences if s.endswith('?'))\n    return float(question_count) / len(sentences) if sentences else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.03587759980012366,
        "mean_shap": -0.002834994719834862,
        "std_shap": 0.03978144983649852,
        "min_shap": -0.1075042236387984,
        "max_shap": 0.05571318441663037
      },
      "rank": 11
    },
    {
      "feature_index": 269,
      "feature_name": "feature_269",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of sentences that ask questions'\n    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n    question_count = sum(1 for s in sentences if s.endswith('?'))\n    return float(question_count) / len(sentences) if sentences else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.03431649643308173,
        "mean_shap": -0.002681968245549192,
        "std_shap": 0.03817465816468934,
        "min_shap": -0.10119392457419966,
        "max_shap": 0.054960419737306254
      },
      "rank": 12
    },
    {
      "feature_index": 176,
      "feature_name": "feature_176",
      "feature_code": "def feature(text: str) -> float:\n    'Count of commas in the text'\n    return float(text.count(','))\n",
      "shap_statistics": {
        "mean_abs_shap": 0.03421091668115055,
        "mean_shap": 0.0026135621915293664,
        "std_shap": 0.03641069031863969,
        "min_shap": -0.06250609355071357,
        "max_shap": 0.056355837424343566
      },
      "rank": 13
    },
    {
      "feature_index": 15,
      "feature_name": "feature_15",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of sentences that ask questions'\n    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n    question_count = sum(1 for s in sentences if s.endswith('?'))\n    return float(question_count) / len(sentences) if sentences else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.03178867251367571,
        "mean_shap": -0.0023787886899926686,
        "std_shap": 0.03530269439032171,
        "min_shap": -0.1007358260284419,
        "max_shap": 0.04942710832831327
      },
      "rank": 14
    },
    {
      "feature_index": 19,
      "feature_name": "feature_19",
      "feature_code": "def feature(text: str) -> float:\n    \"Total count of comma occurrences in the text\"\n    return float(text.count(','))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.031277970211433935,
        "mean_shap": 0.00173725824721613,
        "std_shap": 0.03314880090436126,
        "min_shap": -0.05500358767790994,
        "max_shap": 0.05085255637053127
      },
      "rank": 15
    },
    {
      "feature_index": 28,
      "feature_name": "feature_28",
      "feature_code": "def feature(text: str) -> float:\n    \"Total count of comma occurrences in the text\"\n    return float(text.count(','))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.03047910244478008,
        "mean_shap": 0.0022433363332960915,
        "std_shap": 0.03241896294390287,
        "min_shap": -0.055927171668263276,
        "max_shap": 0.051694116679852666
      },
      "rank": 16
    },
    {
      "feature_index": 136,
      "feature_name": "feature_136",
      "feature_code": "def feature(text: str) -> float:\n    \"Total count of comma occurrences in the text\"\n    return float(text.count(','))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.02936288736727881,
        "mean_shap": 0.0021559767941135136,
        "std_shap": 0.031064636169091005,
        "min_shap": -0.0519471679750225,
        "max_shap": 0.048497694176861235
      },
      "rank": 17
    },
    {
      "feature_index": 208,
      "feature_name": "feature_208",
      "feature_code": "def feature(text: str) -> float:\n    'Count of unique words in the text'\n    words = set(re.findall(r'\\w+', text.lower()))\n    return float(len(words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.027928937494437128,
        "mean_shap": -0.006999286984867035,
        "std_shap": 0.047712074306627945,
        "min_shap": -0.049286257741131,
        "max_shap": 0.30299575686225527
      },
      "rank": 18
    },
    {
      "feature_index": 232,
      "feature_name": "feature_232",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of nested clauses identified by commas\"\n    clause_count = text.count(',')\n    return float(clause_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.027696011696479124,
        "mean_shap": 0.0019511887018249315,
        "std_shap": 0.028954198550547317,
        "min_shap": -0.047944985199458875,
        "max_shap": 0.04462976300332729
      },
      "rank": 19
    },
    {
      "feature_index": 82,
      "feature_name": "feature_82",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of stop words in the text\"\n    stop_words = set(['the', 'is', 'in', 'and', 'to', 'a', 'that', 'it', 'of', 'for', 'on', 'with', 'as', 'this', 'by', 'an', 'are', 'be'])  # Sample stop words\n    words = text.lower().split()\n    stop_word_count = sum(1 for word in words if word in stop_words)\n    return float(stop_word_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.02203824129632941,
        "mean_shap": 0.0031221189057190363,
        "std_shap": 0.022953015317999082,
        "min_shap": -0.04318113750087892,
        "max_shap": 0.038404606728479
      },
      "rank": 20
    },
    {
      "feature_index": 100,
      "feature_name": "feature_100",
      "feature_code": "def feature(text: str) -> float:\n    \"Average negative sentiment score based on a simple word list\"\n    negative_words = {'no', 'not', 'never', 'none', 'nobody', 'cannot', 'shouldn', 'wouldn'}\n    word_list = text.lower().split()\n    negative_count = sum(1 for word in word_list if word in negative_words)\n    return float(negative_count) / len(word_list) if word_list else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.019130393672077445,
        "mean_shap": 0.004291411573123369,
        "std_shap": 0.026980174730798164,
        "min_shap": -0.20490627160620628,
        "max_shap": 0.026094551798896658
      },
      "rank": 21
    },
    {
      "feature_index": 166,
      "feature_name": "feature_166",
      "feature_code": "def feature(text: str) -> float:\n    'Average length of paragraphs in terms of sentences'\n    paragraphs = text.split('\\n')\n    sentence_count = sum(text.count('.') + text.count('!') + text.count('?') for text in paragraphs)\n    if len(paragraphs) == 0:\n        return 0.0\n    return float(sentence_count) / len(paragraphs)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.019046935784761982,
        "mean_shap": -9.170818888267188e-05,
        "std_shap": 0.024066272075629943,
        "min_shap": -0.06786859563192901,
        "max_shap": 0.05039644322644758
      },
      "rank": 22
    },
    {
      "feature_index": 205,
      "feature_name": "feature_205",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of transitions between question and answer format in the text\"\n    questions = text.count('?')\n    answers = text.count(':')\n    return float(questions / (answers + 1))  # To avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.017833316825199737,
        "mean_shap": -0.004652128791540018,
        "std_shap": 0.029025345125713663,
        "min_shap": -0.11421682789843982,
        "max_shap": 0.03160382584698808
      },
      "rank": 23
    },
    {
      "feature_index": 153,
      "feature_name": "feature_153",
      "feature_code": "def feature(text: str) -> float:\n    'Frequency of the word \"you\" in the text'\n    word_count = text.split().count('you')\n    total_words = len(text.split())\n    if total_words == 0:\n        return 0.0\n    return float(word_count) / total_words\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.017816722301747672,
        "mean_shap": -0.000781860689970612,
        "std_shap": 0.022213470837493973,
        "min_shap": -0.06212802633930216,
        "max_shap": 0.05464490082388644
      },
      "rank": 24
    },
    {
      "feature_index": 331,
      "feature_name": "feature_331",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of commas to total words in the text'\n    word_count = len(text.split())\n    comma_count = text.count(',')\n    return comma_count / word_count if word_count > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.017675439888607324,
        "mean_shap": 0.0019800946523825056,
        "std_shap": 0.02187714977518766,
        "min_shap": -0.043584899900112925,
        "max_shap": 0.06293995539998426
      },
      "rank": 25
    },
    {
      "feature_index": 128,
      "feature_name": "feature_128",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of sentences that contain more than 20 characters\"\n    sentences = re.split(r'[.!?]+', text)\n    long_sentences = [s for s in sentences if len(s) > 20]\n    return len(long_sentences) / (len(sentences) if len(sentences) > 0 else 1)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.016735865431490235,
        "mean_shap": -0.002908654471391698,
        "std_shap": 0.036798979089016366,
        "min_shap": -0.23377147753489305,
        "max_shap": 0.02152907798814082
      },
      "rank": 26
    },
    {
      "feature_index": 62,
      "feature_name": "feature_62",
      "feature_code": "def feature(text: str) -> float:\n    \"Total number of characters in the text excluding whitespace\"\n    return float(len(text.replace(' ', '').replace('\\n', '')))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0158467271983495,
        "mean_shap": -0.0008097215939060125,
        "std_shap": 0.020339290812847993,
        "min_shap": -0.024832045874476735,
        "max_shap": 0.06608266992900011
      },
      "rank": 27
    },
    {
      "feature_index": 271,
      "feature_name": "feature_271",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of lowercase letters to total characters in the text'\n    lowercase_count = sum(1 for c in text if c.islower())\n    total_chars = len(text)\n    if total_chars == 0:\n        return 0.0\n    return float(lowercase_count) / total_chars\n",
      "shap_statistics": {
        "mean_abs_shap": 0.015002883808586916,
        "mean_shap": -0.000441976515735145,
        "std_shap": 0.01711998468374749,
        "min_shap": -0.03965246151594979,
        "max_shap": 0.03938162820247491
      },
      "rank": 28
    },
    {
      "feature_index": 117,
      "feature_name": "feature_117",
      "feature_code": "def feature(text: str) -> float:\n    \"Sum of lengths of all words in the text\"\n    words = text.split()\n    return float(sum(len(word) for word in words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.014787240419227032,
        "mean_shap": -0.00036906332573481655,
        "std_shap": 0.019159811892501898,
        "min_shap": -0.019385250762044316,
        "max_shap": 0.060538945543584306
      },
      "rank": 29
    },
    {
      "feature_index": 175,
      "feature_name": "feature_175",
      "feature_code": "def feature(text: str) -> float:\n    \"Punctuation density in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    return punctuation_count / (len(text) + 1)  # adding 1 to avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.014759061852112221,
        "mean_shap": 0.0016460610051305918,
        "std_shap": 0.020386167326047956,
        "min_shap": -0.07444443389447984,
        "max_shap": 0.0343206007641386
      },
      "rank": 30
    },
    {
      "feature_index": 94,
      "feature_name": "feature_94",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of complex words to total words in the text\"\n    complex_word_count = sum(1 for word in text.split() if len(word) > 3 and sum(c.isalpha() for c in word) > 3)\n    total_words = len(text.split())\n    return float(complex_word_count / total_words) if total_words > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.014299198568440957,
        "mean_shap": -0.0002820848454515275,
        "std_shap": 0.017738793104204276,
        "min_shap": -0.053621335488215266,
        "max_shap": 0.04054557341949936
      },
      "rank": 31
    },
    {
      "feature_index": 222,
      "feature_name": "feature_222",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of words containing at least one uppercase letter to total words\"\n    words = text.split()\n    if not words:\n        return 0.0\n    upper_case_words = sum(1 for word in words if any(c.isupper() for c in word))\n    return upper_case_words / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.014281621555331745,
        "mean_shap": 0.0006720930042803838,
        "std_shap": 0.01654610227272242,
        "min_shap": -0.02561932798284146,
        "max_shap": 0.047831986554629474
      },
      "rank": 32
    },
    {
      "feature_index": 356,
      "feature_name": "feature_356",
      "feature_code": "def feature(text: str) -> float:\n    'Average length of the last few sentences in the text'\n    sentences = re.split(r'[.!?]+', text)\n    last_sentences = sentences[-3:]  # Last three sentences\n    lengths = [len(s.split()) for s in last_sentences if s.split()]\n    if not lengths:\n        return 0.0\n    return sum(lengths) / len(lengths)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.014160700129746235,
        "mean_shap": -0.00045063086924424287,
        "std_shap": 0.01711290890788203,
        "min_shap": -0.04469439670500196,
        "max_shap": 0.03573085628212536
      },
      "rank": 33
    },
    {
      "feature_index": 159,
      "feature_name": "feature_159",
      "feature_code": "def feature(text: str) -> float:\n    'Count of multi-syllable words in the text'\n    multi_syllable_count = len(re.findall(r'\\b\\w*[aeiou]{2,}\\w*\\b', text))\n    return float(multi_syllable_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.013145678023049692,
        "mean_shap": -0.002385188787096371,
        "std_shap": 0.01573214453851552,
        "min_shap": -0.03433089008471121,
        "max_shap": 0.05091721309588735
      },
      "rank": 34
    },
    {
      "feature_index": 1,
      "feature_name": "feature_1",
      "feature_code": "def feature(text: str) -> float:\n    'Total number of characters in the text excluding whitespace'\n    char_count = sum(1 for c in text if not c.isspace())\n    return float(char_count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.012179980844234037,
        "mean_shap": -0.0005095064699228155,
        "std_shap": 0.015718322790376552,
        "min_shap": -0.019888483943503673,
        "max_shap": 0.0507283216498847
      },
      "rank": 35
    },
    {
      "feature_index": 147,
      "feature_name": "feature_147",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of complex words to total words in the text\"\n    words = text.split()\n    complex_word_count = sum(1 for word in words if len(word) > 2 and not word.isalnum())\n    if not words:\n        return 0.0\n    return float(complex_word_count) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.011985781388049545,
        "mean_shap": 0.0022732055091664503,
        "std_shap": 0.01469323238911011,
        "min_shap": -0.04319274143289906,
        "max_shap": 0.03587812262967476
      },
      "rank": 36
    },
    {
      "feature_index": 182,
      "feature_name": "feature_182",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of stopwords in the text\"\n    stopwords = set(['the', 'is', 'in', 'a', 'an', 'and', 'to', 'of', 'that', 'it'])  # Example stopwords\n    words = text.split()\n    stopword_count = sum(1 for word in words if word.lower() in stopwords)\n    return float(stopword_count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.011733215723330841,
        "mean_shap": 0.0025400548009570927,
        "std_shap": 0.013292363581574523,
        "min_shap": -0.03401953519690096,
        "max_shap": 0.02302208454889288
      },
      "rank": 37
    },
    {
      "feature_index": 54,
      "feature_name": "feature_54",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of implementation-specific keywords in the text\"\n    keywords = ['need', 'important', 'should', 'must', 'best', 'recommend']\n    count = sum(text.lower().count(keyword) for keyword in keywords)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.011588843382607199,
        "mean_shap": -0.0019548416402775932,
        "std_shap": 0.013410518530944934,
        "min_shap": -0.03286389518660015,
        "max_shap": 0.030613066976864115
      },
      "rank": 38
    },
    {
      "feature_index": 158,
      "feature_name": "feature_158",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of alphanumeric characters to total characters in the text\"\n    alphanumeric_count = sum(1 for c in text if c.isalnum())\n    total_chars = len(text)\n    return float(alphanumeric_count) / total_chars if total_chars > 0 else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.011571811320675284,
        "mean_shap": 9.233859207542883e-05,
        "std_shap": 0.014502168901350228,
        "min_shap": -0.04464572755949749,
        "max_shap": 0.02511989827458602
      },
      "rank": 39
    },
    {
      "feature_index": 318,
      "feature_name": "feature_318",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the word 'I' in the text\"\n    words = text.split()\n    return float(words.count('I')) / (len(words) + 1)  # Adding 1 to avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.011427920754576335,
        "mean_shap": 0.001556171919936632,
        "std_shap": 0.013440362477512706,
        "min_shap": -0.03911102885843599,
        "max_shap": 0.025462037329464532
      },
      "rank": 40
    },
    {
      "feature_index": 227,
      "feature_name": "feature_227",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of clauses in sentences\"\n    sentences = re.split(r'[.!?]+', text)\n    clause_counts = [len(re.findall(r',|;', s)) + 1 for s in sentences if s]\n    return float(statistics.mean(clause_counts)) if clause_counts else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.011054407967537665,
        "mean_shap": 0.0008391250716527938,
        "std_shap": 0.013061850574873062,
        "min_shap": -0.031071058001098405,
        "max_shap": 0.0312872858491012
      },
      "rank": 41
    },
    {
      "feature_index": 241,
      "feature_name": "feature_241",
      "feature_code": "def feature(text: str) -> float:\n    \"Average punctuation per sentence\"\n    sentence_count = len(re.findall(r'[.!?]', text))\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    return float(punctuation_count / sentence_count) if sentence_count > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.01033150272774364,
        "mean_shap": 6.149096549837624e-05,
        "std_shap": 0.012392146520537165,
        "min_shap": -0.038248723180782054,
        "max_shap": 0.020889748297958866
      },
      "rank": 42
    },
    {
      "feature_index": 180,
      "feature_name": "feature_180",
      "feature_code": "def feature(text: str) -> float:\n    'Average length of the longest word in each sentence'\n    sentences = re.split(r'[.!?]+', text)\n    max_word_lengths = []\n    for s in sentences:\n        words = s.split()\n        if words:\n            max_word_lengths.append(max(len(word) for word in words))\n    if not max_word_lengths:\n        return 0.0\n    return float(statistics.mean(max_word_lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.009708378062724345,
        "mean_shap": -0.0006367679493677635,
        "std_shap": 0.014025340737003265,
        "min_shap": -0.08328350193700403,
        "max_shap": 0.022276056592383395
      },
      "rank": 43
    },
    {
      "feature_index": 139,
      "feature_name": "feature_139",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of uppercase words in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    uppercase_count = sum(1 for word in words if word.isupper())\n    return float(uppercase_count) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00927064703998884,
        "mean_shap": -0.00026493569377034125,
        "std_shap": 0.012450412401431105,
        "min_shap": -0.052965267985848594,
        "max_shap": 0.018308712919369443
      },
      "rank": 44
    },
    {
      "feature_index": 214,
      "feature_name": "feature_214",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of uppercase words in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    uppercase_count = sum(1 for word in words if word.isupper())\n    return float(uppercase_count) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.009115320339261981,
        "mean_shap": 0.000146848138891061,
        "std_shap": 0.011869038717742256,
        "min_shap": -0.04597148614433567,
        "max_shap": 0.01980739808339959
      },
      "rank": 45
    },
    {
      "feature_index": 242,
      "feature_name": "feature_242",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of uppercase words in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    uppercase_count = sum(1 for word in words if word.isupper())\n    return float(uppercase_count) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.009049978635899389,
        "mean_shap": 0.00045433484942320287,
        "std_shap": 0.011627367678686369,
        "min_shap": -0.04551168921524299,
        "max_shap": 0.018597700047021087
      },
      "rank": 46
    },
    {
      "feature_index": 37,
      "feature_name": "feature_37",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the word 'I' in the text\"\n    words = text.split()\n    count = words.count('I')\n    return count / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.008685450200626848,
        "mean_shap": 0.0011088045623128134,
        "std_shap": 0.010229516103341559,
        "min_shap": -0.03217450980402812,
        "max_shap": 0.01913605690122465
      },
      "rank": 47
    },
    {
      "feature_index": 106,
      "feature_name": "feature_106",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of punctuation marks to total words\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    total_words = len(text.split())\n    return punctuation_count / total_words if total_words > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.008651008588352885,
        "mean_shap": 0.0004991637473540939,
        "std_shap": 0.011057355796681715,
        "min_shap": -0.03829413775492786,
        "max_shap": 0.01947693946646697
      },
      "rank": 48
    },
    {
      "feature_index": 244,
      "feature_name": "feature_244",
      "feature_code": "def feature(text: str) -> float:\n    'Total number of distinct punctuation marks in the text'\n    punctuation_marks = set(c for c in text if c in string.punctuation)\n    return float(len(punctuation_marks))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.008289509163552736,
        "mean_shap": 0.0009026901606969144,
        "std_shap": 0.01699410449278038,
        "min_shap": -0.12167834013714587,
        "max_shap": 0.01941537683105024
      },
      "rank": 49
    },
    {
      "feature_index": 199,
      "feature_name": "feature_199",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    lengths = [len(word) for word in unique_words]\n    mean_length = statistics.mean(lengths)\n    variance = statistics.mean((x - mean_length) ** 2 for x in lengths)\n    return float(variance ** 0.5)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.008220483433065676,
        "mean_shap": 0.003506649164613605,
        "std_shap": 0.011436156461984277,
        "min_shap": -0.0634292972912097,
        "max_shap": 0.02406736664395926
      },
      "rank": 50
    },
    {
      "feature_index": 154,
      "feature_name": "feature_154",
      "feature_code": "def feature(text: str) -> float:\n    'Density of nouns in the text based on a simple heuristic'\n    words = text.split()\n    noun_count = sum(1 for word in words if word.lower() in {'i', 'you', 'he', 'she', 'it', 'we', 'they'})\n    return float(noun_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.007402091260905438,
        "mean_shap": -0.00012235810583864753,
        "std_shap": 0.00937114844098905,
        "min_shap": -0.016557511142851013,
        "max_shap": 0.035251453995535115
      },
      "rank": 51
    },
    {
      "feature_index": 103,
      "feature_name": "feature_103",
      "feature_code": "def feature(text: str) -> float:\n    'Density of question marks in the text'\n    question_count = text.count('?')\n    total_length = len(text)\n    if total_length == 0:\n        return 0.0\n    return float(question_count) / total_length\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.007322708952978733,
        "mean_shap": -0.0012549396840406376,
        "std_shap": 0.008411127807670168,
        "min_shap": -0.022484316571365216,
        "max_shap": 0.011454506991915733
      },
      "rank": 52
    },
    {
      "feature_index": 329,
      "feature_name": "feature_329",
      "feature_code": "def feature(text: str) -> float:\n    'Density of nouns in the text based on a simple heuristic'\n    words = text.split()\n    noun_count = sum(1 for word in words if word.lower() in {'i', 'you', 'he', 'she', 'it', 'we', 'they'})\n    return float(noun_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.007120126932271408,
        "mean_shap": -7.54663629258457e-05,
        "std_shap": 0.008943023505369229,
        "min_shap": -0.016044206772201502,
        "max_shap": 0.03257673082816132
      },
      "rank": 53
    },
    {
      "feature_index": 60,
      "feature_name": "feature_60",
      "feature_code": "def feature(text: str) -> float:\n    'Density of question marks in the text'\n    question_count = text.count('?')\n    total_length = len(text)\n    if total_length == 0:\n        return 0.0\n    return float(question_count) / total_length\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.007102420990814984,
        "mean_shap": -0.0010013801015978279,
        "std_shap": 0.008400312828976079,
        "min_shap": -0.02732960134655278,
        "max_shap": 0.010544301210403732
      },
      "rank": 54
    },
    {
      "feature_index": 357,
      "feature_name": "feature_357",
      "feature_code": "def feature(text: str) -> float:\n    \"Density of question marks in the text\"\n    question_count = text.count('?')\n    total_count = len(text)\n    if total_count == 0:\n        return 0.0\n    return question_count / total_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.007093326541673469,
        "mean_shap": -0.0012784941657777188,
        "std_shap": 0.008352834877345382,
        "min_shap": -0.025503907581518378,
        "max_shap": 0.010412894175772429
      },
      "rank": 55
    },
    {
      "feature_index": 76,
      "feature_name": "feature_76",
      "feature_code": "def feature(text: str) -> float:\n    'Density of nouns in the text based on a simple heuristic'\n    words = text.split()\n    noun_count = sum(1 for word in words if word.lower() in {'i', 'you', 'he', 'she', 'it', 'we', 'they'})\n    return float(noun_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.006821764578737544,
        "mean_shap": -0.0002754326144835996,
        "std_shap": 0.008483857493039496,
        "min_shap": -0.015215567227053976,
        "max_shap": 0.027781286250437708
      },
      "rank": 56
    },
    {
      "feature_index": 32,
      "feature_name": "feature_32",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the word 'I' in the text\"\n    words = text.split()\n    count = words.count('I')\n    return count / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.006758187832033244,
        "mean_shap": 0.0010433452321112167,
        "std_shap": 0.008083199545034784,
        "min_shap": -0.02895466796439725,
        "max_shap": 0.016056998492140966
      },
      "rank": 57
    },
    {
      "feature_index": 312,
      "feature_name": "feature_312",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of question marks in the text\"\n    total_chars = len(text)\n    question_marks = text.count('?')\n    return question_marks / total_chars if total_chars > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.006536512434212431,
        "mean_shap": -0.0012719295546884653,
        "std_shap": 0.007585684216895136,
        "min_shap": -0.020681443638163474,
        "max_shap": 0.011184737557277905
      },
      "rank": 58
    },
    {
      "feature_index": 301,
      "feature_name": "feature_301",
      "feature_code": "def feature(text: str) -> float:\n    'Percentage of words that are questions in the text'\n    questions = text.count('?')\n    total_words = len(text.split())\n    return float(questions) / total_words if total_words > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00646905552839396,
        "mean_shap": -0.001330425559477654,
        "std_shap": 0.007610363075515171,
        "min_shap": -0.021355209854747707,
        "max_shap": 0.011203743136527347
      },
      "rank": 59
    },
    {
      "feature_index": 50,
      "feature_name": "feature_50",
      "feature_code": "def feature(text: str) -> float:\n    'Entropy of word frequencies in the text'\n    words = text.split()\n    word_count = len(words)\n    if word_count == 0:\n        return 0.0\n    frequencies = Counter(words)\n    prob = [count / word_count for count in frequencies.values()]\n    entropy = -sum(p * np.log2(p) for p in prob if p > 0)\n    return float(entropy)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0063987970103626885,
        "mean_shap": -0.0005938387789878622,
        "std_shap": 0.0075684346340272445,
        "min_shap": -0.011829899537990575,
        "max_shap": 0.026786108893981687
      },
      "rank": 60
    },
    {
      "feature_index": 77,
      "feature_name": "feature_77",
      "feature_code": "def feature(text: str) -> float:\n    'Count of negation words (e.g., no, not) in the text'\n    negation_words = ['no', 'not', 'never']\n    count = sum(text.lower().count(word) for word in negation_words)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.006010360104201892,
        "mean_shap": -0.001537783379599292,
        "std_shap": 0.007092641597761858,
        "min_shap": -0.02217691966129706,
        "max_shap": 0.009466582704945409
      },
      "rank": 61
    },
    {
      "feature_index": 132,
      "feature_name": "feature_132",
      "feature_code": "def feature(text: str) -> float:\n    'Count of negation words (e.g., no, not) in the text'\n    negation_words = ['no', 'not', 'never']\n    count = sum(text.lower().count(word) for word in negation_words)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.005983735885677042,
        "mean_shap": -0.0015030896046804045,
        "std_shap": 0.007131776785954338,
        "min_shap": -0.027293124366624184,
        "max_shap": 0.01021741188532342
      },
      "rank": 62
    },
    {
      "feature_index": 36,
      "feature_name": "feature_36",
      "feature_code": "def feature(text: str) -> float:\n    'Count of negation words (e.g., no, not) in the text'\n    negation_words = ['no', 'not', 'never']\n    count = sum(text.lower().count(word) for word in negation_words)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0054191432535001935,
        "mean_shap": -0.0013540981660678018,
        "std_shap": 0.006521493270628438,
        "min_shap": -0.02330232318309767,
        "max_shap": 0.00897379343040879
      },
      "rank": 63
    },
    {
      "feature_index": 259,
      "feature_name": "feature_259",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of nouns to total words in the text based on a simple heuristic'\n    words = text.split()\n    count_nouns = len(re.findall(r'\\b\\w*(tion|ment|ness|ity|ship|er|or|ing)\\b', text, re.I))  # naive noun pattern\n    return float(count_nouns / len(words)) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.005378007904523875,
        "mean_shap": -8.109266003498324e-05,
        "std_shap": 0.006753117715724438,
        "min_shap": -0.015803455140393254,
        "max_shap": 0.026810120359739332
      },
      "rank": 64
    },
    {
      "feature_index": 223,
      "feature_name": "feature_223",
      "feature_code": "def feature(text: str) -> float:\n    \"Percentage of words that are questions based on '?', 'How', 'What', or 'Will'\"\n    words = text.split()\n    question_words = sum(1 for word in words if word.lower().startswith(('how', 'what', 'will')))\n    return float(question_words) / max(len(words), 1)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.005124526198211425,
        "mean_shap": 0.0018399193315644933,
        "std_shap": 0.006051880981185241,
        "min_shap": -0.028246975152719157,
        "max_shap": 0.014301145791638319
      },
      "rank": 65
    },
    {
      "feature_index": 297,
      "feature_name": "feature_297",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of nouns to total words in the text based on a simple heuristic'\n    words = text.split()\n    count_nouns = len(re.findall(r'\\b\\w*(tion|ment|ness|ity|ship|er|or|ing)\\b', text, re.I))  # naive noun pattern\n    return float(count_nouns / len(words)) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.005097548982213243,
        "mean_shap": -0.00017807445247731925,
        "std_shap": 0.006313995428887619,
        "min_shap": -0.01255884606641984,
        "max_shap": 0.0238383550768515
      },
      "rank": 66
    },
    {
      "feature_index": 186,
      "feature_name": "feature_186",
      "feature_code": "def feature(text: str) -> float:\n    'Count of \"you\" or \"your\" in the text'\n    return float(text.lower().count('you') + text.lower().count('your'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.005094747645225386,
        "mean_shap": -0.00022620033359507522,
        "std_shap": 0.008750142571286212,
        "min_shap": -0.025220770398448757,
        "max_shap": 0.0435668618707767
      },
      "rank": 67
    },
    {
      "feature_index": 270,
      "feature_name": "feature_270",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of question marks to total sentences'\n    sentence_count = len(re.split(r'[.!?]+', text)) - 1\n    question_count = text.count('?')\n    if sentence_count == 0:\n        return 0.0\n    return float(question_count) / sentence_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.005056389327248845,
        "mean_shap": -4.041247825421021e-05,
        "std_shap": 0.005730735167144078,
        "min_shap": -0.016044807915617694,
        "max_shap": 0.012712437741469945
      },
      "rank": 68
    },
    {
      "feature_index": 156,
      "feature_name": "feature_156",
      "feature_code": "def feature(text: str) -> float:\n    \"Percentage of words that are questions based on '?', 'How', 'What', or 'Will'\"\n    words = text.split()\n    question_words = sum(1 for word in words if word.lower().startswith(('how', 'what', 'will')))\n    return float(question_words) / max(len(words), 1)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004867985755124693,
        "mean_shap": 0.0017779178636623356,
        "std_shap": 0.005644513973247994,
        "min_shap": -0.024053896603868523,
        "max_shap": 0.015015287713288163
      },
      "rank": 69
    },
    {
      "feature_index": 53,
      "feature_name": "feature_53",
      "feature_code": "def feature(text: str) -> float:\n    \"Average sentence length in characters\"\n    sentences = re.split(r'[.!?]+', text)\n    if not sentences or len(sentences) == 1 and sentences[0] == '':\n        return 0.0\n    return sum(len(s.strip()) for s in sentences if s.strip()) / len(sentences)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004664581663239884,
        "mean_shap": 0.0010931237694704718,
        "std_shap": 0.006399532354447168,
        "min_shap": -0.02471091806777098,
        "max_shap": 0.012726371828816474
      },
      "rank": 70
    },
    {
      "feature_index": 261,
      "feature_name": "feature_261",
      "feature_code": "def feature(text: str) -> float:\n    \"Density of multi-syllable words in the text\"\n    multi_syllable_pattern = re.compile(r'\\b\\w*(?:[aeiou]{2,}\\w*){2,}\\b', re.IGNORECASE)\n    multi_syllable_count = len(re.findall(multi_syllable_pattern, text))\n    return float(multi_syllable_count) / len(text.split()) if text.split() else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004601032804287378,
        "mean_shap": -0.000494392859850156,
        "std_shap": 0.006918575285669069,
        "min_shap": -0.0318909836647349,
        "max_shap": 0.006609538630610013
      },
      "rank": 71
    },
    {
      "feature_index": 96,
      "feature_name": "feature_96",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of complex words to total words in the text\"\n    complex_words = len([word for word in text.split() if len(word) > 2 and re.search(r'[aeiou]', word)])\n    total_words = len(text.split())\n    return complex_words / total_words if total_words > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004498497082943974,
        "mean_shap": -3.083092797438436e-06,
        "std_shap": 0.005258751986173337,
        "min_shap": -0.013864028190942249,
        "max_shap": 0.011548869119929878
      },
      "rank": 72
    },
    {
      "feature_index": 296,
      "feature_name": "feature_296",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation to total characters in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    total_count = len(text)\n    return punctuation_count / total_count if total_count > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004466499934922074,
        "mean_shap": 0.00038460266942907153,
        "std_shap": 0.006033289321224346,
        "min_shap": -0.020882788700332375,
        "max_shap": 0.01025078248258552
      },
      "rank": 73
    },
    {
      "feature_index": 163,
      "feature_name": "feature_163",
      "feature_code": "def feature(text: str) -> float:\n    'Entropy of the text based on character frequency'\n    from collections import Counter\n    import math\n    \n    char_counts = Counter(text)\n    total_chars = sum(char_counts.values())\n    if total_chars == 0:\n        return 0.0\n    \n    entropy = -sum((count / total_chars) * math.log(count / total_chars, 2) for count in char_counts.values())\n    return entropy\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004421356961405543,
        "mean_shap": 0.00016824253342335476,
        "std_shap": 0.006098024112508115,
        "min_shap": -0.021010177191062754,
        "max_shap": 0.025494087930637583
      },
      "rank": 74
    },
    {
      "feature_index": 101,
      "feature_name": "feature_101",
      "feature_code": "def feature(text: str) -> float:\n    \"Punctuation count as a percentage of total characters\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    total_count = len(text)\n    if total_count == 0:\n        return 0.0\n    return float(punctuation_count) / total_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004420115600296887,
        "mean_shap": 0.0004393558667070237,
        "std_shap": 0.00577295509411955,
        "min_shap": -0.02099522755316714,
        "max_shap": 0.010618958732898316
      },
      "rank": 75
    },
    {
      "feature_index": 85,
      "feature_name": "feature_85",
      "feature_code": "def feature(text: str) -> float:\n    'Punctuation diversity measure in the text'\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    unique_punctuation = len(set(c for c in text if c in string.punctuation))\n    return float(unique_punctuation / (punctuation_count + 1))  # avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004406927072408475,
        "mean_shap": -0.0018193271572655826,
        "std_shap": 0.005175198928183938,
        "min_shap": -0.020126015733917247,
        "max_shap": 0.01200886801158516
      },
      "rank": 76
    },
    {
      "feature_index": 169,
      "feature_name": "feature_169",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of specific conjunctions in the text\"\n    conjunctions = ['and', 'but', 'or', 'so']\n    count = sum(text.lower().count(conj) for conj in conjunctions)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0043759661400590375,
        "mean_shap": -0.00022412678008143332,
        "std_shap": 0.004796959368989106,
        "min_shap": -0.013066919426887888,
        "max_shap": 0.009735604719889176
      },
      "rank": 77
    },
    {
      "feature_index": 119,
      "feature_name": "feature_119",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of complex words (3+ syllables) to total words in the text'\n    complex_words = re.findall(r'\\b\\w+[aeiou]{1,3}\\w*\\b', text)\n    return len(complex_words) / len(text.split()) if text.split() else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004343928622460658,
        "mean_shap": 0.0012558600160915423,
        "std_shap": 0.005857966354196556,
        "min_shap": -0.026137553178733487,
        "max_shap": 0.010713663704014305
      },
      "rank": 78
    },
    {
      "feature_index": 273,
      "feature_name": "feature_273",
      "feature_code": "def feature(text: str) -> float:\n    \"Average punctuation mark density in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    if len(text) == 0:\n        return 0.0\n    return punctuation_count / len(text)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0043206652609335166,
        "mean_shap": 0.00044475783279498054,
        "std_shap": 0.005715086856025633,
        "min_shap": -0.02072840003866167,
        "max_shap": 0.011812575002347355
      },
      "rank": 79
    },
    {
      "feature_index": 178,
      "feature_name": "feature_178",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of complex words to total words in the text\"\n    complex_words = len([word for word in text.split() if len(word) > 2 and re.search(r'[aeiou]', word)])\n    total_words = len(text.split())\n    return complex_words / total_words if total_words > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004292626739281492,
        "mean_shap": 7.491820116450122e-05,
        "std_shap": 0.00503944580333514,
        "min_shap": -0.013394528157390185,
        "max_shap": 0.010546438353326082
      },
      "rank": 80
    },
    {
      "feature_index": 238,
      "feature_name": "feature_238",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of punctuation characters to total characters in the text'\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    total_characters = len(text)\n    if total_characters == 0:\n        return 0.0\n    return punctuation_count / total_characters\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004256348960526112,
        "mean_shap": 0.00043746585779096597,
        "std_shap": 0.005632889244067916,
        "min_shap": -0.02038422112628131,
        "max_shap": 0.009938085011336334
      },
      "rank": 81
    },
    {
      "feature_index": 204,
      "feature_name": "feature_204",
      "feature_code": "def feature(text: str) -> float:\n    \"Average punctuation mark density in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    if len(text) == 0:\n        return 0.0\n    return punctuation_count / len(text)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004252922987682854,
        "mean_shap": 0.00039030471519070116,
        "std_shap": 0.005508654625846149,
        "min_shap": -0.018538885713544437,
        "max_shap": 0.010104239878785018
      },
      "rank": 82
    },
    {
      "feature_index": 43,
      "feature_name": "feature_43",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of modal verbs in the text\"\n    modal_verbs = ['can', 'could', 'may', 'might', 'must', 'shall', 'should', 'will', 'would']\n    count = sum(text.lower().count(verb) for verb in modal_verbs)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004215788561736975,
        "mean_shap": -0.0003658256499047044,
        "std_shap": 0.005487638794516514,
        "min_shap": -0.010762251993395807,
        "max_shap": 0.02051810640016698
      },
      "rank": 83
    },
    {
      "feature_index": 22,
      "feature_name": "feature_22",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation to total characters in the text\"\n    total_chars = len(text)\n    if total_chars == 0:\n        return 0.0\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    return punctuation_count / total_chars\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004186182434029983,
        "mean_shap": 0.0005030213161883945,
        "std_shap": 0.005332389458408087,
        "min_shap": -0.020041948625793605,
        "max_shap": 0.008770549563867554
      },
      "rank": 84
    },
    {
      "feature_index": 200,
      "feature_name": "feature_200",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of specific keywords related to seeking advice to total words\"\n    keywords = re.findall(r'\\b(should|could|need|ought)\\b', text, re.IGNORECASE)\n    total_words = len(text.split())\n    return float(len(keywords) / total_words) if total_words > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0040398301119212365,
        "mean_shap": -2.526450463011595e-05,
        "std_shap": 0.005412651080734474,
        "min_shap": -0.009366994076865028,
        "max_shap": 0.028469205282825254
      },
      "rank": 85
    },
    {
      "feature_index": 284,
      "feature_name": "feature_284",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation to total characters in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    total_chars = len(text)\n    return float(punctuation_count / total_chars) if total_chars > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.004022594108236191,
        "mean_shap": 0.00026431972717628674,
        "std_shap": 0.005236774482246302,
        "min_shap": -0.015659826009382444,
        "max_shap": 0.00919711178136277
      },
      "rank": 86
    },
    {
      "feature_index": 347,
      "feature_name": "feature_347",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of capitalized words to total words in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    capitalized_count = sum(1 for word in words if word.istitle())\n    return float(capitalized_count) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.003923464433418705,
        "mean_shap": -0.0005516878900084155,
        "std_shap": 0.0050167399287896946,
        "min_shap": -0.012489416576818907,
        "max_shap": 0.021438520620042277
      },
      "rank": 87
    },
    {
      "feature_index": 285,
      "feature_name": "feature_285",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of words containing at least one vowel to total words\"\n    words = text.split()\n    if not words:\n        return 0.0\n    vowel_words = sum(1 for word in words if any(c in 'aeiouAEIOU' for c in word))\n    return float(vowel_words) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0038491642332279794,
        "mean_shap": -0.0005535459305994422,
        "std_shap": 0.005118346882671827,
        "min_shap": -0.010353898196013175,
        "max_shap": 0.020904028516256678
      },
      "rank": 88
    },
    {
      "feature_index": 292,
      "feature_name": "feature_292",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of words that start with an uppercase letter\"\n    words = text.split()\n    upper_count = sum(1 for word in words if word and word[0].isupper())\n    return upper_count / len(words) if words else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0038216349512822617,
        "mean_shap": 0.00018872799595180456,
        "std_shap": 0.004538828206958779,
        "min_shap": -0.006564690463213151,
        "max_shap": 0.012343048447070088
      },
      "rank": 89
    },
    {
      "feature_index": 133,
      "feature_name": "feature_133",
      "feature_code": "def feature(text: str) -> float:\n    \"Average punctuation mark density in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    if len(text) == 0:\n        return 0.0\n    return punctuation_count / len(text)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00379608037361833,
        "mean_shap": 0.00034518239541467017,
        "std_shap": 0.0050481066813173004,
        "min_shap": -0.019163478803588343,
        "max_shap": 0.009857203539589295
      },
      "rank": 90
    },
    {
      "feature_index": 299,
      "feature_name": "feature_299",
      "feature_code": "def feature(text: str) -> float:\n    'Count of unique words in the text'\n    unique_words = set(text.split())\n    return float(len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.003729197001358568,
        "mean_shap": 1.4458118822527319e-05,
        "std_shap": 0.004368292957001656,
        "min_shap": -0.006264423174768998,
        "max_shap": 0.011830433683138
      },
      "rank": 91
    },
    {
      "feature_index": 42,
      "feature_name": "feature_42",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation characters to total characters in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    total_chars = len(text)\n    if total_chars == 0:\n        return 0.0\n    return punctuation_count / total_chars\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0037263868684526023,
        "mean_shap": 0.00019923722994774973,
        "std_shap": 0.005167362996372892,
        "min_shap": -0.01859387738132627,
        "max_shap": 0.008262180294217616
      },
      "rank": 92
    },
    {
      "feature_index": 9,
      "feature_name": "feature_9",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation to total characters in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    total_count = len(text)\n    if total_count == 0:\n        return 0.0\n    return float(punctuation_count) / total_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0036290518959860444,
        "mean_shap": 0.0003148652842568966,
        "std_shap": 0.004942679881056482,
        "min_shap": -0.019287388858218017,
        "max_shap": 0.007117962285040209
      },
      "rank": 93
    },
    {
      "feature_index": 5,
      "feature_name": "feature_5",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation marks to total characters\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    if len(text) == 0:\n        return 0.0\n    return punctuation_count / len(text)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.003615578099630522,
        "mean_shap": 0.00034970793463469737,
        "std_shap": 0.004874794133453099,
        "min_shap": -0.018387590579543055,
        "max_shap": 0.008958720729168349
      },
      "rank": 94
    },
    {
      "feature_index": 352,
      "feature_name": "feature_352",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of punctuation marks to total characters in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    if len(text) == 0:\n        return 0.0\n    return punctuation_count / len(text)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.003584801803510729,
        "mean_shap": 0.00018684296094315572,
        "std_shap": 0.005057504583776585,
        "min_shap": -0.020515737740259686,
        "max_shap": 0.008737612965334044
      },
      "rank": 95
    },
    {
      "feature_index": 288,
      "feature_name": "feature_288",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of sentences that ask questions\"\n    question_count = text.count('?')\n    total_sentences = len(re.findall(r'[.!?]', text)) + (1 if len(text) > 0 else 0)\n    if total_sentences == 0:\n        return 0.0\n    return float(question_count / total_sentences)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0035676517702069054,
        "mean_shap": -0.00039422974896180166,
        "std_shap": 0.004273341716675794,
        "min_shap": -0.012691501792558138,
        "max_shap": 0.007570895726294734
      },
      "rank": 96
    },
    {
      "feature_index": 303,
      "feature_name": "feature_303",
      "feature_code": "def feature(text: str) -> float:\n    \"Density of non-alphanumeric characters in the text\"\n    non_alnum_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    return float(non_alnum_count) / len(text) if len(text) > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0034871902083615566,
        "mean_shap": 0.0004624711457259589,
        "std_shap": 0.00462771275453369,
        "min_shap": -0.01543346553569326,
        "max_shap": 0.00820442831166815
      },
      "rank": 97
    },
    {
      "feature_index": 240,
      "feature_name": "feature_240",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique words in the text\"\n    unique_words = set(text.split())\n    return float(len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0034782304273283226,
        "mean_shap": -0.00022284052246966462,
        "std_shap": 0.00454525868591358,
        "min_shap": -0.004960606652049649,
        "max_shap": 0.01309723182566412
      },
      "rank": 98
    },
    {
      "feature_index": 181,
      "feature_name": "feature_181",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of complex words (words longer than 2 syllables)'\n    complex_word_pattern = r'\\b\\w{3,}\\b'  # We consider words with at least 3 characters\n    words = re.findall(complex_word_pattern, text)\n    complex_words_count = sum(1 for word in words if len(re.findall(r'[aeiou]+', word)) > 2)\n    return complex_words_count / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0034539118046585807,
        "mean_shap": 7.887731026605834e-05,
        "std_shap": 0.004458553482169972,
        "min_shap": -0.013092005601529491,
        "max_shap": 0.012688585262306228
      },
      "rank": 99
    },
    {
      "feature_index": 367,
      "feature_name": "feature_367",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length of the three longest words in the text\"\n    words = sorted(text.split(), key=len, reverse=True)[:3]\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words)) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.003449759659602541,
        "mean_shap": 0.0010877992004322986,
        "std_shap": 0.005197316386341844,
        "min_shap": -0.03565784107245057,
        "max_shap": 0.008043577578355013
      },
      "rank": 100
    },
    {
      "feature_index": 99,
      "feature_name": "feature_99",
      "feature_code": "def feature(text: str) -> float:\n    \"Density of stop words in the text\"\n    stop_words = set(['the', 'is', 'in', 'and', 'to', 'a', 'that', 'it', 'of', 'for', 'you', 'on', 'with'])\n    words = text.split()\n    stop_word_count = len([word for word in words if word.lower() in stop_words])\n    return float(stop_word_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.003420434140977805,
        "mean_shap": -0.00029370166395317125,
        "std_shap": 0.004465632946778836,
        "min_shap": -0.015370307977906669,
        "max_shap": 0.011220808185149155
      },
      "rank": 101
    },
    {
      "feature_index": 335,
      "feature_name": "feature_335",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of words that are nouns based on naive heuristic (ending in s or other common noun markers)\"\n    words = text.split()\n    noun_count = sum(1 for word in words if word.endswith('s') or word.endswith('tion'))\n    return noun_count / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0033169946791591033,
        "mean_shap": -1.2909426308083093e-05,
        "std_shap": 0.004037652954125264,
        "min_shap": -0.009208381573571315,
        "max_shap": 0.011048999464088112
      },
      "rank": 102
    },
    {
      "feature_index": 283,
      "feature_name": "feature_283",
      "feature_code": "def feature(text: str) -> float:\n    \"Total number of words in the text\"\n    return float(len(text.split()))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0032999224170557956,
        "mean_shap": -0.00014029654456043834,
        "std_shap": 0.004823400345956179,
        "min_shap": -0.005838946397684072,
        "max_shap": 0.01893014571719357
      },
      "rank": 103
    },
    {
      "feature_index": 251,
      "feature_name": "feature_251",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of words that start with a capital letter\"\n    capitalized_count = sum(1 for word in text.split() if word.istitle())\n    return float(capitalized_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.003287584348040164,
        "mean_shap": 0.001258063583941425,
        "std_shap": 0.004277806321279339,
        "min_shap": -0.01613794006392518,
        "max_shap": 0.022388679722684372
      },
      "rank": 104
    },
    {
      "feature_index": 113,
      "feature_name": "feature_113",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of numeric values to total words in the text\"\n    numbers = len(re.findall(r'\\d+', text))\n    total_words = len(text.split())\n    return float(numbers / total_words) if total_words > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.003254296082825153,
        "mean_shap": -5.662727400019482e-05,
        "std_shap": 0.005751101938747887,
        "min_shap": -0.00520132846351742,
        "max_shap": 0.03149276576334421
      },
      "rank": 105
    },
    {
      "feature_index": 328,
      "feature_name": "feature_328",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of capitalized words in the text\"\n    capitalized_count = sum(1 for word in text.split() if word.istitle())\n    return float(capitalized_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0031112983114030698,
        "mean_shap": 0.0010606724916234767,
        "std_shap": 0.004056895777033343,
        "min_shap": -0.013197944759865915,
        "max_shap": 0.02379441630037168
      },
      "rank": 106
    },
    {
      "feature_index": 25,
      "feature_name": "feature_25",
      "feature_code": "def feature(text: str) -> float:\n    'Count of specific keywords related to advice (e.g., \"should\", \"could\")'\n    keywords = ['should', 'could', 'might', 'recommend']\n    count = sum(text.lower().count(keyword) for keyword in keywords)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0030989273697357503,
        "mean_shap": 0.00010006066709528583,
        "std_shap": 0.0038765488840760806,
        "min_shap": -0.007450708831283545,
        "max_shap": 0.011162071519380113
      },
      "rank": 107
    },
    {
      "feature_index": 249,
      "feature_name": "feature_249",
      "feature_code": "def feature(text: str) -> float:\n    \"Total number of words in the text\"\n    return float(len(text.split()))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0030841832673329304,
        "mean_shap": 0.0001500573583091365,
        "std_shap": 0.004612101289010536,
        "min_shap": -0.0050698415788681265,
        "max_shap": 0.016444835082934588
      },
      "rank": 108
    },
    {
      "feature_index": 239,
      "feature_name": "feature_239",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique verbs in the text\"\n    verbs = {'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did'}  # Sample verb list\n    words = set(text.lower().split())\n    unique_verbs = words.intersection(verbs)\n    return float(len(unique_verbs))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0030359504103114206,
        "mean_shap": -0.00042429191502592936,
        "std_shap": 0.0038236995495729716,
        "min_shap": -0.015819376044452667,
        "max_shap": 0.00768546883954251
      },
      "rank": 109
    },
    {
      "feature_index": 343,
      "feature_name": "feature_343",
      "feature_code": "def feature(text: str) -> float:\n    'Count of unique words in the text'\n    unique_words = set(text.split())\n    return float(len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0030015421419941437,
        "mean_shap": -4.167335813683844e-05,
        "std_shap": 0.003786938503476202,
        "min_shap": -0.00515595851638037,
        "max_shap": 0.012855779882671283
      },
      "rank": 110
    },
    {
      "feature_index": 29,
      "feature_name": "feature_29",
      "feature_code": "def feature(text: str) -> float:\n    'Frequency of the word \"I\" in the text'\n    i_count = text.lower().count('i')\n    total_words = len(text.split())\n    if total_words == 0:\n        return 0.0\n    return float(i_count) / total_words\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0029721633911600244,
        "mean_shap": 8.912456594493514e-06,
        "std_shap": 0.004525896472820112,
        "min_shap": -0.02858292801000741,
        "max_shap": 0.00964345833867391
      },
      "rank": 111
    },
    {
      "feature_index": 310,
      "feature_name": "feature_310",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of upper-case letters in the text\"\n    upper_case_count = sum(1 for c in text if c.isupper())\n    return float(upper_case_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002950160693395731,
        "mean_shap": 0.0010568650753078612,
        "std_shap": 0.003754221854152822,
        "min_shap": -0.008808863021237318,
        "max_shap": 0.023324403863879736
      },
      "rank": 112
    },
    {
      "feature_index": 30,
      "feature_name": "feature_30",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002872497216995216,
        "mean_shap": 0.0004298799275866219,
        "std_shap": 0.003238397048533179,
        "min_shap": -0.004722241808519079,
        "max_shap": 0.009158748593338118
      },
      "rank": 113
    },
    {
      "feature_index": 258,
      "feature_name": "feature_258",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique words in the text\"\n    unique_words = set(text.split())\n    return float(len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0028702664474781776,
        "mean_shap": 5.236678505501463e-05,
        "std_shap": 0.0033557917399343433,
        "min_shap": -0.00434651126854234,
        "max_shap": 0.009806425649743426
      },
      "rank": 114
    },
    {
      "feature_index": 20,
      "feature_name": "feature_20",
      "feature_code": "def feature(text: str) -> float:\n    'Frequency of the word \"human\" in the text'\n    count = text.lower().count('human')\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002870086773206199,
        "mean_shap": -0.001019423296965821,
        "std_shap": 0.0031338946532152214,
        "min_shap": -0.00888812723854543,
        "max_shap": 0.007449657832149759
      },
      "rank": 115
    },
    {
      "feature_index": 142,
      "feature_name": "feature_142",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of words that start with an uppercase letter\"\n    words = text.split()\n    if not words:\n        return 0.0\n    capitalized_count = sum(1 for word in words if word[0].isupper())\n    return float(capitalized_count) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0028334478385562156,
        "mean_shap": 5.533862920271965e-05,
        "std_shap": 0.0034147921406339006,
        "min_shap": -0.005302975807087379,
        "max_shap": 0.010009357506231038
      },
      "rank": 116
    },
    {
      "feature_index": 75,
      "feature_name": "feature_75",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of average word length to average sentence length'\n    words = text.split()\n    sentences = re.split(r'[.!?]+', text)\n    if not words or not sentences:\n        return 0.0\n    avg_word_length = sum(len(word) for word in words) / len(words)\n    avg_sentence_length = sum(len(s.split()) for s in sentences) / len(sentences)\n    return avg_word_length / avg_sentence_length\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002828263079191455,
        "mean_shap": -0.00030735376713601987,
        "std_shap": 0.0033449023745315515,
        "min_shap": -0.008041676530064825,
        "max_shap": 0.007207182404918128
      },
      "rank": 117
    },
    {
      "feature_index": 190,
      "feature_name": "feature_190",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the word 'I' in the text\"\n    return float(text.lower().count('i')) / len(text.split()) if text.split() else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0027917594452055174,
        "mean_shap": 8.129762875575736e-05,
        "std_shap": 0.004051299525436421,
        "min_shap": -0.02180476247222501,
        "max_shap": 0.008721180585861184
      },
      "rank": 118
    },
    {
      "feature_index": 267,
      "feature_name": "feature_267",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of the number of sentences to the number of words\"\n    sentence_count = len(re.findall(r'[.!?]', text))\n    word_count = len(text.split())\n    if word_count == 0:\n        return 0.0\n    return float(sentence_count) / word_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002745599811396266,
        "mean_shap": -0.000280173896420948,
        "std_shap": 0.003649060138498583,
        "min_shap": -0.017222729409234305,
        "max_shap": 0.00594147822631742
      },
      "rank": 119
    },
    {
      "feature_index": 326,
      "feature_name": "feature_326",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of clauses per sentence in the text\"\n    sentences = re.split(r'[.!?]+', text)\n    clause_count = sum(len(re.findall(r',', sentence)) + 1 for sentence in sentences if sentence)\n    total_sentences = len(sentences)\n    if total_sentences == 0:\n        return 0.0\n    return float(clause_count) / total_sentences\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0027163059752464396,
        "mean_shap": -0.0001564150296633345,
        "std_shap": 0.003553379565859974,
        "min_shap": -0.011182697071684107,
        "max_shap": 0.011195341043010086
      },
      "rank": 120
    },
    {
      "feature_index": 290,
      "feature_name": "feature_290",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of sentence lengths in words\"\n    sentences = text.split('. ')\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    return float(statistics.pstdev(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0027141863200619586,
        "mean_shap": -0.0010791370138419334,
        "std_shap": 0.0033012021973927636,
        "min_shap": -0.01162625274474336,
        "max_shap": 0.010740046695580126
      },
      "rank": 121
    },
    {
      "feature_index": 233,
      "feature_name": "feature_233",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of exclamation marks to total sentences\"\n    exclamations = text.count('!')\n    sentences = text.count('.') + text.count('!') + text.count('?')\n    if sentences == 0:\n        return 0.0\n    return float(exclamations) / sentences\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0026596884440665863,
        "mean_shap": -0.0008130156655230392,
        "std_shap": 0.002950639976100673,
        "min_shap": -0.007128696595871445,
        "max_shap": 0.008239421106516607
      },
      "rank": 122
    },
    {
      "feature_index": 56,
      "feature_name": "feature_56",
      "feature_code": "def feature(text: str) -> float:\n    'Average number of words per sentence'\n    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n    word_counts = [len(s.split()) for s in sentences]\n    return float(sum(word_counts)) / len(sentences) if sentences else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0026540819961350646,
        "mean_shap": 0.0002895852273593758,
        "std_shap": 0.003498775767991683,
        "min_shap": -0.01662534447137977,
        "max_shap": 0.005678962447474834
      },
      "rank": 123
    },
    {
      "feature_index": 309,
      "feature_name": "feature_309",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0026447034427036146,
        "mean_shap": 0.00039484826404686445,
        "std_shap": 0.003013016417137856,
        "min_shap": -0.004155340152483946,
        "max_shap": 0.008793119020993884
      },
      "rank": 124
    },
    {
      "feature_index": 144,
      "feature_name": "feature_144",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of words longer than 5 letters in the text\"\n    words = text.split()\n    long_words_count = sum(1 for word in words if len(word) > 5)\n    return float(long_words_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002521203332164873,
        "mean_shap": -0.0003272241567392745,
        "std_shap": 0.0030549179034761666,
        "min_shap": -0.007059029561412417,
        "max_shap": 0.007871399043474971
      },
      "rank": 125
    },
    {
      "feature_index": 221,
      "feature_name": "feature_221",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    return lower_count / (upper_count + 1)  # Prevent division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002503815100687157,
        "mean_shap": 0.0003800335085546682,
        "std_shap": 0.0027917511739385314,
        "min_shap": -0.00453345074536394,
        "max_shap": 0.007291022800282022
      },
      "rank": 126
    },
    {
      "feature_index": 319,
      "feature_name": "feature_319",
      "feature_code": "def feature(text: str) -> float:\n    'Frequency of stop words in the text'\n    stop_words = set(['the', 'is', 'in', 'at', 'which', 'on', 'and', 'a', 'to', 'of'])\n    words = text.lower().split()\n    stop_word_count = sum(1 for word in words if word in stop_words)\n    return stop_word_count / max(len(words), 1)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0024846388632933846,
        "mean_shap": 0.0003958901086784358,
        "std_shap": 0.0036272801302558917,
        "min_shap": -0.010281587517212372,
        "max_shap": 0.015915742342633005
      },
      "rank": 127
    },
    {
      "feature_index": 345,
      "feature_name": "feature_345",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the word 'I' in the text\"\n    return float(text.lower().count('i')) / len(text.split()) if text.split() else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002483654247361506,
        "mean_shap": 3.860276070975001e-05,
        "std_shap": 0.0037297358961019098,
        "min_shap": -0.021236066151931795,
        "max_shap": 0.007779987996082096
      },
      "rank": 128
    },
    {
      "feature_index": 332,
      "feature_name": "feature_332",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation to total characters in the text\"\n    total_chars = len(text)\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    return punctuation_count / total_chars if total_chars > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0023818030217056686,
        "mean_shap": 0.000291957817065055,
        "std_shap": 0.0031785735928708393,
        "min_shap": -0.010842389111118466,
        "max_shap": 0.00528603873601072
      },
      "rank": 129
    },
    {
      "feature_index": 353,
      "feature_name": "feature_353",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002308998722884588,
        "mean_shap": 0.0003383753874062492,
        "std_shap": 0.0026160014051060166,
        "min_shap": -0.004127581929906419,
        "max_shap": 0.007326392423469296
      },
      "rank": 130
    },
    {
      "feature_index": 264,
      "feature_name": "feature_264",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of syllables per word in the text\"\n    words = text.split()\n    syllable_count = sum(sum(1 for char in word if char in 'aeiou') for word in words)\n    return float(syllable_count / len(words)) if words else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002255056011814013,
        "mean_shap": 0.0002674074589337202,
        "std_shap": 0.0026240067165519076,
        "min_shap": -0.005727039431588588,
        "max_shap": 0.005372862515572741
      },
      "rank": 131
    },
    {
      "feature_index": 13,
      "feature_name": "feature_13",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of words longer than 5 letters in the text\"\n    words = text.split()\n    long_words_count = sum(1 for word in words if len(word) > 5)\n    return float(long_words_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002248628754624305,
        "mean_shap": -0.0005139282797329923,
        "std_shap": 0.002831373661282262,
        "min_shap": -0.006734945295490332,
        "max_shap": 0.008122504790462882
      },
      "rank": 132
    },
    {
      "feature_index": 143,
      "feature_name": "feature_143",
      "feature_code": "def feature(text: str) -> float:\n    'Count of specific punctuation marks in the text'\n    return float(text.count(';') + text.count(':'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0022362624400031543,
        "mean_shap": -0.0003655675333475314,
        "std_shap": 0.0026302765765662812,
        "min_shap": -0.012248861549084654,
        "max_shap": 0.004928776578142835
      },
      "rank": 133
    },
    {
      "feature_index": 90,
      "feature_name": "feature_90",
      "feature_code": "def feature(text: str) -> float:\n    \"Average length of unique sentences in words\"\n    sentences = re.split(r'[.!?]+', text)\n    unique_lengths = {len(s.split()) for s in sentences if s.strip()}\n    if not unique_lengths:\n        return 0.0\n    return float(statistics.mean(unique_lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002195429070101054,
        "mean_shap": 0.0005291664380289484,
        "std_shap": 0.002752104701171622,
        "min_shap": -0.010409267707042997,
        "max_shap": 0.005175711372722359
      },
      "rank": 134
    },
    {
      "feature_index": 79,
      "feature_name": "feature_79",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of adjectives in the text\"\n    adjectives_pattern = r'\\b\\w+ly\\b|\\b(?:a|an|the|this|that|these|those)\\b|\\b\\w+ed\\b'\n    adjectives = re.findall(adjectives_pattern, text, re.IGNORECASE)\n    return float(len(adjectives))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0021489525403534087,
        "mean_shap": 0.0004673501110216091,
        "std_shap": 0.002764902828975171,
        "min_shap": -0.009675939836065276,
        "max_shap": 0.009381988098920263
      },
      "rank": 135
    },
    {
      "feature_index": 4,
      "feature_name": "feature_4",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00214521405767518,
        "mean_shap": 0.0002159107255197545,
        "std_shap": 0.0023857120426409133,
        "min_shap": -0.0035572763751485774,
        "max_shap": 0.005496249862257814
      },
      "rank": 136
    },
    {
      "feature_index": 27,
      "feature_name": "feature_27",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0021430538847734657,
        "mean_shap": 0.00011271368204065963,
        "std_shap": 0.002389079589297576,
        "min_shap": -0.0038401466641400346,
        "max_shap": 0.0064513314446448325
      },
      "rank": 137
    },
    {
      "feature_index": 201,
      "feature_name": "feature_201",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique unigrams in the text\"\n    words = set(text.split())\n    return float(len(words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0021124678776357543,
        "mean_shap": -0.0001075447304237182,
        "std_shap": 0.0023162041751254928,
        "min_shap": -0.003438493207057493,
        "max_shap": 0.006010361745040942
      },
      "rank": 138
    },
    {
      "feature_index": 236,
      "feature_name": "feature_236",
      "feature_code": "def feature(text: str) -> float:\n    'Count of figures of speech used in the text (e.g., metaphor, simile)'\n    figures_of_speech = re.findall(r'\\b(as|like|than)\\b', text, re.IGNORECASE)  # Simplified detection\n    return float(len(figures_of_speech))\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0020883682819455534,
        "mean_shap": 0.00036017688531248215,
        "std_shap": 0.002694397590812828,
        "min_shap": -0.006262617262625527,
        "max_shap": 0.009818670488462277
      },
      "rank": 139
    },
    {
      "feature_index": 23,
      "feature_name": "feature_23",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.002082168199217733,
        "mean_shap": 0.0003474682268644311,
        "std_shap": 0.002358446614778294,
        "min_shap": -0.0035155357267445315,
        "max_shap": 0.0070021614081940894
      },
      "rank": 140
    },
    {
      "feature_index": 302,
      "feature_name": "feature_302",
      "feature_code": "def feature(text: str) -> float:\n    'Total number of unique words in the text'\n    unique_words = set(text.split())\n    return float(len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0020770653537242664,
        "mean_shap": -0.00018193304918306561,
        "std_shap": 0.0029286147351585755,
        "min_shap": -0.003409530069240102,
        "max_shap": 0.011683822081101122
      },
      "rank": 141
    },
    {
      "feature_index": 360,
      "feature_name": "feature_360",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of stop words to total words in the text'\n    stop_words = {'the', 'is', 'in', 'and', 'to', 'a', 'of', 'that', 'it', 'you'}\n    words = text.split()\n    stop_word_count = sum(1 for word in words if word.lower() in stop_words)\n    return float(stop_word_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0020140576739006034,
        "mean_shap": 3.8593485349577844e-05,
        "std_shap": 0.002740104787018858,
        "min_shap": -0.006612880019969268,
        "max_shap": 0.011066296605815108
      },
      "rank": 142
    },
    {
      "feature_index": 110,
      "feature_name": "feature_110",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of stop words in the text\"\n    stop_words = set(['the', 'is', 'in', 'and', 'to', 'a', 'of', 'that', 'it', 'you'])\n    count = sum(1 for word in text.lower().split() if word in stop_words)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.001994309213212533,
        "mean_shap": 0.0009271724825669067,
        "std_shap": 0.0022588169747124695,
        "min_shap": -0.007840437002780663,
        "max_shap": 0.007428449824468276
      },
      "rank": 143
    },
    {
      "feature_index": 26,
      "feature_name": "feature_26",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0018878123985876605,
        "mean_shap": 0.00015989335245437353,
        "std_shap": 0.0021442594143687467,
        "min_shap": -0.003995927935874141,
        "max_shap": 0.005119565832289368
      },
      "rank": 144
    },
    {
      "feature_index": 131,
      "feature_name": "feature_131",
      "feature_code": "def feature(text: str) -> float:\n    'Count of conjunctions in the text'\n    conjunctions = ['and', 'but', 'or', 'nor', 'for', 'so', 'yet']\n    count = sum(text.lower().split().count(conj) for conj in conjunctions)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.001879501689432023,
        "mean_shap": -0.0005365687218362972,
        "std_shap": 0.0020794636375165492,
        "min_shap": -0.005166199604484874,
        "max_shap": 0.0043784262472929825
      },
      "rank": 145
    },
    {
      "feature_index": 124,
      "feature_name": "feature_124",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of numeric digits to total words in the text\"\n    words = text.split()\n    digit_count = sum(1 for word in words if any(char.isdigit() for char in word))\n    return float(digit_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0018575616979327097,
        "mean_shap": -0.0002217489155559732,
        "std_shap": 0.003105489265847186,
        "min_shap": -0.004131335337261026,
        "max_shap": 0.01971612818299077
      },
      "rank": 146
    },
    {
      "feature_index": 3,
      "feature_name": "feature_3",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.001808853745832802,
        "mean_shap": 0.00021633694319190332,
        "std_shap": 0.002044824108426691,
        "min_shap": -0.0031500088996110833,
        "max_shap": 0.005348026912587352
      },
      "rank": 147
    },
    {
      "feature_index": 257,
      "feature_name": "feature_257",
      "feature_code": "def feature(text: str) -> float:\n    \"Count the number of paragraphs in the text, indicated by double line breaks\"\n    return float(text.count('\\n\\n'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0017399743442330217,
        "mean_shap": -0.00018710659507128186,
        "std_shap": 0.0029061840435961727,
        "min_shap": -0.006089135191620341,
        "max_shap": 0.016637583842749725
      },
      "rank": 148
    },
    {
      "feature_index": 7,
      "feature_name": "feature_7",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of conjunctions in the text\"\n    conjunctions = ['and', 'but', 'or', 'nor', 'for', 'so', 'yet']\n    word_list = text.lower().split()\n    conjunction_count = sum(word_list.count(conj) for conj in conjunctions)\n    return float(conjunction_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0017399581889103672,
        "mean_shap": -0.0005798545082722578,
        "std_shap": 0.001906217050776795,
        "min_shap": -0.00588800007853849,
        "max_shap": 0.003985514804852521
      },
      "rank": 149
    },
    {
      "feature_index": 348,
      "feature_name": "feature_348",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of long words (more than 6 characters) to total words'\n    words = text.split()\n    if not words:\n        return 0.0\n    long_words = sum(1 for word in words if len(word) > 6)\n    return long_words / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0017304266689512856,
        "mean_shap": -0.0002244683296658487,
        "std_shap": 0.0024236059363485457,
        "min_shap": -0.006272357976760535,
        "max_shap": 0.008302741139212713
      },
      "rank": 150
    },
    {
      "feature_index": 150,
      "feature_name": "feature_150",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of words with more than 7 characters\"\n    long_words = len([word for word in text.split() if len(word) > 7])\n    return float(long_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.001700657129526818,
        "mean_shap": -0.00012240275227945848,
        "std_shap": 0.0021567583570176515,
        "min_shap": -0.0046780937031135825,
        "max_shap": 0.006598930840562022
      },
      "rank": 151
    },
    {
      "feature_index": 287,
      "feature_name": "feature_287",
      "feature_code": "def feature(text: str) -> float:\n    'Count of conjunctions in the text'\n    conjunctions = ['and', 'but', 'or', 'nor', 'for', 'so', 'yet']\n    count = sum(text.lower().split().count(conj) for conj in conjunctions)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.001685312324843483,
        "mean_shap": -0.0004673813627222675,
        "std_shap": 0.0018814342847701946,
        "min_shap": -0.004336281060360754,
        "max_shap": 0.0043808510636748794
      },
      "rank": 152
    },
    {
      "feature_index": 122,
      "feature_name": "feature_122",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0016818750647211232,
        "mean_shap": 0.0001687121427514313,
        "std_shap": 0.0019371856477937545,
        "min_shap": -0.003966505449347,
        "max_shap": 0.004942982319770896
      },
      "rank": 153
    },
    {
      "feature_index": 341,
      "feature_name": "feature_341",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of specific keywords ('help', 'what', 'why') in the text\"\n    keywords = ['help', 'what', 'why']\n    count = sum(text.lower().count(keyword) for keyword in keywords)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0016343506011555317,
        "mean_shap": -0.00024461335588798214,
        "std_shap": 0.002110811247577146,
        "min_shap": -0.007568216635190811,
        "max_shap": 0.005443066384575402
      },
      "rank": 154
    },
    {
      "feature_index": 197,
      "feature_name": "feature_197",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of conjunctions in the text\"\n    conjunctions = ['and', 'but', 'or', 'nor', 'for', 'so', 'yet']\n    word_list = text.lower().split()\n    conjunction_count = sum(word_list.count(conj) for conj in conjunctions)\n    return float(conjunction_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0016125826100456561,
        "mean_shap": -0.000419936032711434,
        "std_shap": 0.0019619303550806565,
        "min_shap": -0.006413751689067445,
        "max_shap": 0.005324186107876832
      },
      "rank": 155
    },
    {
      "feature_index": 212,
      "feature_name": "feature_212",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of numeric digits to total characters in the text\"\n    digit_count = sum(c.isdigit() for c in text)\n    return digit_count / len(text) if len(text) > 0 else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0016016809464577144,
        "mean_shap": 2.8581654674993636e-05,
        "std_shap": 0.0031086942943603707,
        "min_shap": -0.003400357299696744,
        "max_shap": 0.016956191703708504
      },
      "rank": 156
    },
    {
      "feature_index": 141,
      "feature_name": "feature_141",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of conjunctions in the text\"\n    conjunctions = {'and', 'but', 'or', 'nor', 'for', 'so', 'yet'}\n    words = text.lower().split()\n    count = sum(1 for word in words if word in conjunctions)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0016006779837012377,
        "mean_shap": -0.00033818229112678107,
        "std_shap": 0.001849788724704043,
        "min_shap": -0.005121901070343903,
        "max_shap": 0.003818867350666708
      },
      "rank": 157
    },
    {
      "feature_index": 248,
      "feature_name": "feature_248",
      "feature_code": "def feature(text: str) -> float:\n    'Percentage of words that are longer than 6 characters'\n    words = text.split()\n    long_word_count = sum(1 for word in words if len(word) > 6)\n    total_words = len(words)\n    if total_words == 0:\n        return 0.0\n    return float(long_word_count) / total_words * 100\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00156977236065785,
        "mean_shap": -0.00016096356655309545,
        "std_shap": 0.0022020286266506654,
        "min_shap": -0.005158674357079759,
        "max_shap": 0.008504164587567293
      },
      "rank": 158
    },
    {
      "feature_index": 320,
      "feature_name": "feature_320",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique stop words in the text\"\n    stop_words = {'the', 'is', 'at', 'which', 'on', 'for', 'this', 'a', 'an', 'and'}\n    words = text.lower().split()\n    unique_stop_words = set(word for word in words if word in stop_words)\n    return float(len(unique_stop_words))\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0015649438145598639,
        "mean_shap": 0.0005801580251994859,
        "std_shap": 0.0020660994908103616,
        "min_shap": -0.005864408118202297,
        "max_shap": 0.009393977041671959
      },
      "rank": 159
    },
    {
      "feature_index": 364,
      "feature_name": "feature_364",
      "feature_code": "def feature(text: str) -> float:\n    'Average sentence length in characters'\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.strip()) for s in sentences if s.strip()]\n    if not lengths:\n        return 0.0\n    return float(sum(lengths)) / len(lengths)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0015596140853497917,
        "mean_shap": 0.0006235950622672075,
        "std_shap": 0.002309420972940888,
        "min_shap": -0.011449589713071898,
        "max_shap": 0.006242503662171309
      },
      "rank": 160
    },
    {
      "feature_index": 196,
      "feature_name": "feature_196",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of positive sentiment words in the text\"\n    positive_words = ['good', 'great', 'happy', 'love', 'excellent', 'wonderful']\n    count = sum(text.lower().count(word) for word in positive_words)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0015335241716708454,
        "mean_shap": -0.00034815159668319563,
        "std_shap": 0.002111372658630284,
        "min_shap": -0.0038070546818497106,
        "max_shap": 0.007932446105838627
      },
      "rank": 161
    },
    {
      "feature_index": 224,
      "feature_name": "feature_224",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of total words to the number of sentences\"\n    sentences = re.split(r'[.!?]+', text)\n    words = text.split()\n    if not sentences or not words:\n        return 0.0\n    return float(len(words)) / len(sentences)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0014924514725493095,
        "mean_shap": -0.0001271909995794453,
        "std_shap": 0.0018135153441919594,
        "min_shap": -0.005787531774939401,
        "max_shap": 0.00333144731125991
      },
      "rank": 162
    },
    {
      "feature_index": 256,
      "feature_name": "feature_256",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0014908029697691578,
        "mean_shap": 0.00026669587550128703,
        "std_shap": 0.0017075515814178278,
        "min_shap": -0.002213733845653979,
        "max_shap": 0.004542585139389896
      },
      "rank": 163
    },
    {
      "feature_index": 220,
      "feature_name": "feature_220",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of words that appear more than once in the text\"\n    word_counts = Counter(text.split())\n    repeat_word_count = sum(1 for count in word_counts.values() if count > 1)\n    return float(repeat_word_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0014790272096985551,
        "mean_shap": 0.0004757514577197938,
        "std_shap": 0.0019162831794879568,
        "min_shap": -0.006295099981226724,
        "max_shap": 0.005704655827616946
      },
      "rank": 164
    },
    {
      "feature_index": 74,
      "feature_name": "feature_74",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique verbs in the text\"\n    words = text.split()\n    verbs = set(word for word in words if word.lower() in {'do', 'make', 'have', 'be', 'can', 'could', 'should', 'would', 'will', 'may', 'might'})\n    return float(len(verbs))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0014672494459486676,
        "mean_shap": -0.0001960833262282563,
        "std_shap": 0.001868040349572315,
        "min_shap": -0.006126718335149988,
        "max_shap": 0.00797251090492335
      },
      "rank": 165
    },
    {
      "feature_index": 213,
      "feature_name": "feature_213",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lowercase_count = sum(1 for c in text if c.islower())\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return lowercase_count / (uppercase_count + 1)  # Avoid division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0014657710100225412,
        "mean_shap": 4.333253758376775e-05,
        "std_shap": 0.0017380245892659265,
        "min_shap": -0.00347143118984367,
        "max_shap": 0.004408185516867
      },
      "rank": 166
    },
    {
      "feature_index": 216,
      "feature_name": "feature_216",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique words in the text\"\n    unique_words = set(text.split())\n    return float(len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.001457010151875666,
        "mean_shap": -7.331186424143226e-05,
        "std_shap": 0.0018906452028274766,
        "min_shap": -0.0030017538252940473,
        "max_shap": 0.007486506054517651
      },
      "rank": 167
    },
    {
      "feature_index": 282,
      "feature_name": "feature_282",
      "feature_code": "def feature(text: str) -> float:\n    \"Density of adjectives in the text based on a simple heuristic\"\n    adjectives = sum(1 for word in text.split() if word.lower() in {'good', 'bad', 'happy', 'sad', 'big', 'small', 'hot', 'cold'})\n    return adjectives / len(text.split()) if len(text.split()) > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0014518999182952705,
        "mean_shap": 7.351815022680822e-05,
        "std_shap": 0.0021545915060768883,
        "min_shap": -0.0074493157279440685,
        "max_shap": 0.009423939432446989
      },
      "rank": 168
    },
    {
      "feature_index": 57,
      "feature_name": "feature_57",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of first-person plural pronouns to total pronouns\"\n    first_person_plural = ['we', 'us', 'our', 'ours']\n    total_pronouns = sum(text.lower().count(pronoun) for pronoun in ['I', 'me', 'my', 'you', 'your', 'he', 'him', 'his', 'she', 'her', 'it', 'its', 'we', 'us', 'our', 'they', 'them', 'their'])\n    first_person_count = sum(text.lower().count(pronoun) for pronoun in first_person_plural)\n    return first_person_count / total_pronouns if total_pronouns > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0014480903033843105,
        "mean_shap": -0.0002271129389054309,
        "std_shap": 0.0018128810295357136,
        "min_shap": -0.005065363485680813,
        "max_shap": 0.004837608774437522
      },
      "rank": 169
    },
    {
      "feature_index": 35,
      "feature_name": "feature_35",
      "feature_code": "def feature(text: str) -> float:\n    'Length of the longest word in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    return float(max(len(word) for word in words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0014175501425629134,
        "mean_shap": 0.0006244763966399425,
        "std_shap": 0.0023073120528351344,
        "min_shap": -0.018061452912444615,
        "max_shap": 0.0035512196212997642
      },
      "rank": 170
    },
    {
      "feature_index": 263,
      "feature_name": "feature_263",
      "feature_code": "def feature(text: str) -> float:\n    'Count of uppercase words in the text'\n    uppercase_words = [word for word in text.split() if word.isupper()]\n    return float(len(uppercase_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.001404094616500223,
        "mean_shap": -0.00015399175209645282,
        "std_shap": 0.0018245183892786545,
        "min_shap": -0.007761973181149477,
        "max_shap": 0.0035237407100440505
      },
      "rank": 171
    },
    {
      "feature_index": 272,
      "feature_name": "feature_272",
      "feature_code": "def feature(text: str) -> float:\n    \"Density of vowels in the text\"\n    vowels = sum(1 for c in text.lower() if c in 'aeiou')\n    return vowels / len(text) if len(text) > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013880978822318822,
        "mean_shap": -0.0001344434673530979,
        "std_shap": 0.001833999374743458,
        "min_shap": -0.0073413864727277876,
        "max_shap": 0.0036751286544366084
      },
      "rank": 172
    },
    {
      "feature_index": 294,
      "feature_name": "feature_294",
      "feature_code": "def feature(text: str) -> float:\n    'Frequency of the most common word in the text'\n    from collections import Counter\n    words = text.split()\n    if not words:\n        return 0.0\n    most_common_count = Counter(words).most_common(1)[0][1]\n    return float(most_common_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.001379583968442914,
        "mean_shap": 0.0005159724119224114,
        "std_shap": 0.0016294285887412945,
        "min_shap": -0.0025149344051787004,
        "max_shap": 0.007107657106848597
      },
      "rank": 173
    },
    {
      "feature_index": 64,
      "feature_name": "feature_64",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of first-person plural pronouns to total pronouns\"\n    first_person_plural = ['we', 'us', 'our', 'ours']\n    total_pronouns = sum(text.lower().count(pronoun) for pronoun in ['I', 'me', 'my', 'you', 'your', 'he', 'him', 'his', 'she', 'her', 'it', 'its', 'we', 'us', 'our', 'they', 'them', 'their'])\n    first_person_count = sum(text.lower().count(pronoun) for pronoun in first_person_plural)\n    return first_person_count / total_pronouns if total_pronouns > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013684236241396537,
        "mean_shap": -0.0003299755449889799,
        "std_shap": 0.0017857859074353621,
        "min_shap": -0.006065491438906002,
        "max_shap": 0.003934405513588089
      },
      "rank": 174
    },
    {
      "feature_index": 160,
      "feature_name": "feature_160",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of vowels to total characters in the text\"\n    vowels = sum(1 for char in text.lower() if char in 'aeiou')\n    total_chars = len(text)\n    return float(vowels / total_chars) if total_chars > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013605093813191416,
        "mean_shap": -0.00012221559523640038,
        "std_shap": 0.0018013318724651784,
        "min_shap": -0.007888264200848276,
        "max_shap": 0.00498968826738045
      },
      "rank": 175
    },
    {
      "feature_index": 187,
      "feature_name": "feature_187",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of words that are longer than 6 characters'\n    words = text.split()\n    long_words_count = sum(1 for word in words if len(word) > 6)\n    if len(words) == 0:\n        return 0.0\n    return long_words_count / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013541520476668806,
        "mean_shap": -0.0001964229123836114,
        "std_shap": 0.0019281806147456177,
        "min_shap": -0.005272915873915772,
        "max_shap": 0.008014952608579375
      },
      "rank": 176
    },
    {
      "feature_index": 84,
      "feature_name": "feature_84",
      "feature_code": "def feature(text: str) -> float:\n    \"Average syllable count per word in the text\"\n    def count_syllables(word):\n        vowels = 'aeiouy'\n        word = word.lower().strip()\n        if len(word) == 0:\n            return 0\n        syllable_count = sum(1 for char in word if char in vowels)\n        if word.endswith('e'):\n            syllable_count -= 1\n        return max(syllable_count, 1)\n\n    words = text.split()\n    if not words:\n        return 0.0\n    syllable_counts = [count_syllables(word) for word in words]\n    return float(statistics.mean(syllable_counts))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013482254618996132,
        "mean_shap": -0.0002000796991349109,
        "std_shap": 0.0018317162932456178,
        "min_shap": -0.005854207074534105,
        "max_shap": 0.00553074787704594
      },
      "rank": 177
    },
    {
      "feature_index": 286,
      "feature_name": "feature_286",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of uppercase to total characters in the text\"\n    upper_count = sum(1 for c in text if c.isupper())\n    return float(upper_count) / len(text) if len(text) > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013321207693726194,
        "mean_shap": 7.440866600334405e-05,
        "std_shap": 0.0015404076715052264,
        "min_shap": -0.0025433878221963195,
        "max_shap": 0.004300903853242174
      },
      "rank": 178
    },
    {
      "feature_index": 350,
      "feature_name": "feature_350",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the most common word in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    word_counts = Counter(words)\n    most_common_count = word_counts.most_common(1)[0][1]\n    return float(most_common_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013308525747233175,
        "mean_shap": 0.0002935376752636858,
        "std_shap": 0.0015951320153339175,
        "min_shap": -0.005218184197632064,
        "max_shap": 0.0064532982058406
      },
      "rank": 179
    },
    {
      "feature_index": 334,
      "feature_name": "feature_334",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of numeric characters in the text\"\n    digit_count = sum(c.isdigit() for c in text)\n    return float(digit_count) / len(text) if len(text) > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013125878598440272,
        "mean_shap": 3.867204570660584e-05,
        "std_shap": 0.002348924351354053,
        "min_shap": -0.003085303863111657,
        "max_shap": 0.010749963942864676
      },
      "rank": 180
    },
    {
      "feature_index": 10,
      "feature_name": "feature_10",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of numeric characters to total characters in the text'\n    numeric_count = sum(1 for c in text if c.isdigit())\n    if len(text) == 0:\n        return 0.0\n    return numeric_count / len(text)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0013013404675297153,
        "mean_shap": 4.737338125722651e-05,
        "std_shap": 0.002593549332913084,
        "min_shap": -0.002703641675400427,
        "max_shap": 0.014719222055309188
      },
      "rank": 181
    },
    {
      "feature_index": 14,
      "feature_name": "feature_14",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of numeric digits to total characters in the text'\n    digit_count = sum(c.isdigit() for c in text)\n    total_length = len(text)\n    if total_length == 0:\n        return 0.0\n    return float(digit_count) / total_length\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0012885385980636634,
        "mean_shap": 1.5148741737010655e-05,
        "std_shap": 0.0024576678184466986,
        "min_shap": -0.003364493828591342,
        "max_shap": 0.013323603888949775
      },
      "rank": 182
    },
    {
      "feature_index": 289,
      "feature_name": "feature_289",
      "feature_code": "def feature(text: str) -> float:\n    \"Average syllable count per word in the text\"\n    def count_syllables(word):\n        vowels = 'aeiouy'\n        word = word.lower().strip()\n        if len(word) == 0:\n            return 0\n        syllable_count = sum(1 for char in word if char in vowels)\n        if word.endswith('e'):\n            syllable_count -= 1\n        return max(syllable_count, 1)\n\n    words = text.split()\n    if not words:\n        return 0.0\n    syllable_counts = [count_syllables(word) for word in words]\n    return float(statistics.mean(syllable_counts))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0012813647152267755,
        "mean_shap": -0.0001598641334365567,
        "std_shap": 0.001690256648914945,
        "min_shap": -0.006121874172171171,
        "max_shap": 0.004762160324907234
      },
      "rank": 183
    },
    {
      "feature_index": 228,
      "feature_name": "feature_228",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of numeric characters to total characters\"\n    numeric_count = sum(1 for c in text if c.isdigit())\n    total_count = len(text)\n    if total_count == 0:\n        return 0.0\n    return float(numeric_count) / total_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0012612152659583502,
        "mean_shap": 3.4242457413764724e-05,
        "std_shap": 0.0023594828022494166,
        "min_shap": -0.0029065277503325954,
        "max_shap": 0.01222819657977809
      },
      "rank": 184
    },
    {
      "feature_index": 253,
      "feature_name": "feature_253",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of multi-syllable words in the text\"\n    def syllable_count(word):\n        vowels = 'aeiouy'\n        return len([char for char in word if char in vowels])\n    \n    words = text.split()\n    multi_syllable_count = sum(1 for word in words if syllable_count(word) >= 3)\n    return float(multi_syllable_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0012216953306808881,
        "mean_shap": -0.00014167698776725574,
        "std_shap": 0.0016202940303119246,
        "min_shap": -0.0027545417224287888,
        "max_shap": 0.006115868144721655
      },
      "rank": 185
    },
    {
      "feature_index": 87,
      "feature_name": "feature_87",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of uppercase letters in the text'\n    uppercase_count = sum(1 for c in text if c.isupper())\n    return uppercase_count / len(text) if text else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0012041996157839225,
        "mean_shap": -4.3157000428934395e-05,
        "std_shap": 0.0013980881781070675,
        "min_shap": -0.0024763545283149075,
        "max_shap": 0.004193884176782355
      },
      "rank": 186
    },
    {
      "feature_index": 298,
      "feature_name": "feature_298",
      "feature_code": "def feature(text: str) -> float:\n    'Count of unique words in the text'\n    unique_words = set(text.split())\n    return float(len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0011969180740139084,
        "mean_shap": -0.0001728463933034984,
        "std_shap": 0.0015371931922138278,
        "min_shap": -0.0024649444273538096,
        "max_shap": 0.0058910676328796565
      },
      "rank": 187
    },
    {
      "feature_index": 91,
      "feature_name": "feature_91",
      "feature_code": "def feature(text: str) -> float:\n    'Length of the longest word in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    return float(max(len(word) for word in words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0011900606744187042,
        "mean_shap": 0.0003443933140851835,
        "std_shap": 0.002003434399401327,
        "min_shap": -0.014073699130777556,
        "max_shap": 0.0025741553691225627
      },
      "rank": 188
    },
    {
      "feature_index": 70,
      "feature_name": "feature_70",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique bi-grams in the text\"\n    words = text.split()\n    bi_grams = set((words[i], words[i+1]) for i in range(len(words)-1))\n    return float(len(bi_grams))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0011740840351890324,
        "mean_shap": -7.513119227879455e-05,
        "std_shap": 0.0016129561514138281,
        "min_shap": -0.0017751183904021058,
        "max_shap": 0.006188240817391013
      },
      "rank": 189
    },
    {
      "feature_index": 109,
      "feature_name": "feature_109",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of capitalized words in the text\"\n    capitalized_words = sum(1 for word in text.split() if word[0].isupper())\n    return float(capitalized_words)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0011506488135121372,
        "mean_shap": 0.0002885397192484595,
        "std_shap": 0.0015030478380975462,
        "min_shap": -0.0032601105336256147,
        "max_shap": 0.009543991294674209
      },
      "rank": 190
    },
    {
      "feature_index": 307,
      "feature_name": "feature_307",
      "feature_code": "def feature(text: str) -> float:\n    'Average syllables per word'\n    syllable_count = sum(len(re.findall(r'[aeiou]+', word.lower())) for word in text.split())\n    word_count = len(text.split())\n    if word_count == 0:\n        return 0.0\n    return float(syllable_count) / word_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0011448785998963312,
        "mean_shap": 0.00019904142694150543,
        "std_shap": 0.001718131583237025,
        "min_shap": -0.004073656036496173,
        "max_shap": 0.007892959411643558
      },
      "rank": 191
    },
    {
      "feature_index": 210,
      "feature_name": "feature_210",
      "feature_code": "def feature(text: str) -> float:\n    'Count of punctuation marks in the text'\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    return float(punctuation_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0011228577579732077,
        "mean_shap": -0.0007243222717118942,
        "std_shap": 0.00120382243149172,
        "min_shap": -0.0037858915709968024,
        "max_shap": 0.0025282435002179303
      },
      "rank": 192
    },
    {
      "feature_index": 179,
      "feature_name": "feature_179",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of uppercase letters to total characters\"\n    uppercase_count = sum(1 for c in text if c.isupper())\n    total_count = len(text)\n    if total_count == 0:\n        return 0.0\n    return float(uppercase_count) / total_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0011204731203946544,
        "mean_shap": -3.2095285930777465e-05,
        "std_shap": 0.0012872367689882997,
        "min_shap": -0.0027771418355526383,
        "max_shap": 0.003438527696399615
      },
      "rank": 193
    },
    {
      "feature_index": 215,
      "feature_name": "feature_215",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length in the text\"\n    words = text.split()\n    return float(sum(len(word) for word in words) / (len(words) + 1))  # Prevent division by zero\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0011074653316777304,
        "mean_shap": -5.911124486944225e-05,
        "std_shap": 0.0017481769290722743,
        "min_shap": -0.008871532700925262,
        "max_shap": 0.005816103901606008
      },
      "rank": 194
    },
    {
      "feature_index": 207,
      "feature_name": "feature_207",
      "feature_code": "def feature(text: str) -> float:\n    'Measure of text readability using a simple score based on average word length and sentence length'\n    words = text.split()\n    word_count = len(words)\n    if word_count == 0:\n        return 0.0\n    avg_word_length = sum(len(word) for word in words) / word_count\n    sentences = re.split(r'[.!?]+', text)\n    sentence_count = len([s for s in sentences if s.strip()])\n    avg_sentence_length = word_count / sentence_count if sentence_count > 0 else 0.0\n    return avg_word_length / (avg_sentence_length + 1)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010874063931354588,
        "mean_shap": 8.593615373049804e-05,
        "std_shap": 0.001449018370822808,
        "min_shap": -0.005082881203736928,
        "max_shap": 0.0036252988259167424
      },
      "rank": 195
    },
    {
      "feature_index": 67,
      "feature_name": "feature_67",
      "feature_code": "def feature(text: str) -> float:\n    \"Max word length in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    return float(max(len(word) for word in words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010835191311359712,
        "mean_shap": 0.000406788241969762,
        "std_shap": 0.0018611507834724742,
        "min_shap": -0.01614286014921192,
        "max_shap": 0.0022621814641459056
      },
      "rank": 196
    },
    {
      "feature_index": 340,
      "feature_name": "feature_340",
      "feature_code": "def feature(text: str) -> float:\n    'Average sentence length in characters'\n    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n    total_length = sum(len(s) for s in sentences)\n    return total_length / len(sentences) if sentences else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010652255334213118,
        "mean_shap": 6.268772908293434e-05,
        "std_shap": 0.0015157349237666597,
        "min_shap": -0.007404813722654471,
        "max_shap": 0.0025022805308480087
      },
      "rank": 197
    },
    {
      "feature_index": 315,
      "feature_name": "feature_315",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of different verbs in the text\"\n    words = text.split()\n    verb_count = sum(1 for word in words if word.lower() in {'is', 'am', 'are', 'was', 'were', 'be', 'being', 'been', 'have', 'has', 'had', 'do', 'does', 'did'})\n    return float(verb_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010619500254569437,
        "mean_shap": 3.660953798162199e-06,
        "std_shap": 0.0015096568203963343,
        "min_shap": -0.0065372993492579514,
        "max_shap": 0.0034250469948122987
      },
      "rank": 198
    },
    {
      "feature_index": 121,
      "feature_name": "feature_121",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of syllables per word in the text\"\n    words = text.split()\n    syllable_count = sum(len(re.findall(r'[aeiouy]', word.lower())) for word in words)\n    return float(syllable_count) / max(len(words), 1)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010582003740364195,
        "mean_shap": -0.00011283982624382348,
        "std_shap": 0.001458166596131419,
        "min_shap": -0.006820393914427341,
        "max_shap": 0.005355460286891125
      },
      "rank": 199
    },
    {
      "feature_index": 254,
      "feature_name": "feature_254",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of words longer than 7 characters in the text\"\n    long_words = [word for word in text.split() if len(word) > 7]\n    return float(len(long_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010516651194629498,
        "mean_shap": -3.786741609735838e-05,
        "std_shap": 0.001379256667828656,
        "min_shap": -0.003803710990178758,
        "max_shap": 0.003592520366263871
      },
      "rank": 200
    },
    {
      "feature_index": 265,
      "feature_name": "feature_265",
      "feature_code": "def feature(text: str) -> float:\n    'Average sentence length in characters'\n    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n    total_length = sum(len(s) for s in sentences)\n    return total_length / len(sentences) if sentences else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010495813834674758,
        "mean_shap": 0.00010583733228964354,
        "std_shap": 0.0014812716370820676,
        "min_shap": -0.007132591603794863,
        "max_shap": 0.00243700521161329
      },
      "rank": 201
    },
    {
      "feature_index": 89,
      "feature_name": "feature_89",
      "feature_code": "def feature(text: str) -> float:\n    'Count of rhetorical questions based on common patterns'\n    question_patterns = ['is it', 'are you', 'do you', 'what is', 'how do']\n    return float(sum(text.lower().count(pattern) for pattern in question_patterns))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010490496934574473,
        "mean_shap": -0.00031142243881168735,
        "std_shap": 0.0012820938020247873,
        "min_shap": -0.004757091758877425,
        "max_shap": 0.002965814588665811
      },
      "rank": 202
    },
    {
      "feature_index": 137,
      "feature_name": "feature_137",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of capital letters to total characters in the text\"\n    capital_count = sum(1 for c in text if c.isupper())\n    total_count = len(text)\n    return float(capital_count) / total_count if total_count > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010461609786929895,
        "mean_shap": -3.123815829490254e-05,
        "std_shap": 0.0012061634005629276,
        "min_shap": -0.00238629788114431,
        "max_shap": 0.0031471441152010208
      },
      "rank": 203
    },
    {
      "feature_index": 338,
      "feature_name": "feature_338",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique bi-grams in the text\"\n    words = text.split()\n    bi_grams = set((words[i], words[i + 1]) for i in range(len(words) - 1))\n    return float(len(bi_grams))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010236663481177277,
        "mean_shap": 6.693932480544434e-05,
        "std_shap": 0.0011954469236583605,
        "min_shap": -0.0018450492411059363,
        "max_shap": 0.0036488482547751893
      },
      "rank": 204
    },
    {
      "feature_index": 55,
      "feature_name": "feature_55",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of first-person pronouns in the text\"\n    first_person_pronouns = ['I', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours']\n    count = sum(text.lower().count(pronoun.lower()) for pronoun in first_person_pronouns)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010217099029713606,
        "mean_shap": 0.0001283896257186007,
        "std_shap": 0.0013288737126104762,
        "min_shap": -0.0044813339596866675,
        "max_shap": 0.0038004929481317814
      },
      "rank": 205
    },
    {
      "feature_index": 18,
      "feature_name": "feature_18",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of numeric digits to total characters in the text\"\n    digit_count = sum(c.isdigit() for c in text)\n    total_count = len(text)\n    return float(digit_count / total_count) if total_count > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0010202957560358822,
        "mean_shap": -4.910909284368452e-05,
        "std_shap": 0.0018673628871882532,
        "min_shap": -0.0027230638606597886,
        "max_shap": 0.008952285646832701
      },
      "rank": 206
    },
    {
      "feature_index": 111,
      "feature_name": "feature_111",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of different verbs in the text\"\n    words = text.split()\n    verb_count = sum(1 for word in words if word.lower() in {'is', 'am', 'are', 'was', 'were', 'be', 'being', 'been', 'have', 'has', 'had', 'do', 'does', 'did'})\n    return float(verb_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009901425464766153,
        "mean_shap": -4.461214963340231e-05,
        "std_shap": 0.0014404792076471193,
        "min_shap": -0.005553602338318967,
        "max_shap": 0.0030017976894533547
      },
      "rank": 207
    },
    {
      "feature_index": 225,
      "feature_name": "feature_225",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of sentence lengths in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    if not lengths:\n        return 0.0\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009848062611247954,
        "mean_shap": 6.286735415484078e-05,
        "std_shap": 0.0012006966006179879,
        "min_shap": -0.0034973614127055772,
        "max_shap": 0.0027576826828639837
      },
      "rank": 208
    },
    {
      "feature_index": 148,
      "feature_name": "feature_148",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of uppercase letters in the text\"\n    upper_count = sum(1 for c in text if c.isupper())\n    total_count = len(text)\n    return float(upper_count) / total_count if total_count > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009729007800287856,
        "mean_shap": -8.71177333497595e-05,
        "std_shap": 0.0011250043348613153,
        "min_shap": -0.003010162295654625,
        "max_shap": 0.0024210121442618335
      },
      "rank": 209
    },
    {
      "feature_index": 218,
      "feature_name": "feature_218",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of instances of the word 'I' in the text\"\n    return float(text.lower().count('i'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009727038884189991,
        "mean_shap": 0.00027049064168847365,
        "std_shap": 0.001213388911096444,
        "min_shap": -0.005205993655835453,
        "max_shap": 0.00315219853684456
      },
      "rank": 210
    },
    {
      "feature_index": 40,
      "feature_name": "feature_40",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of words longer than 7 characters in the text\"\n    words = text.split()\n    long_words = sum(1 for word in words if len(word) > 7)\n    return long_words / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009643497993356829,
        "mean_shap": -7.768499336657271e-05,
        "std_shap": 0.0012263648333852488,
        "min_shap": -0.002980660103725704,
        "max_shap": 0.004838790258396692
      },
      "rank": 211
    },
    {
      "feature_index": 41,
      "feature_name": "feature_41",
      "feature_code": "def feature(text: str) -> float:\n    \"Sentence length variability measured by standard deviation in sentence length\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    return float(statistics.pstdev(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009605209682956859,
        "mean_shap": 7.952065479451116e-05,
        "std_shap": 0.0011857945902432922,
        "min_shap": -0.0037408891855877004,
        "max_shap": 0.003198508870339487
      },
      "rank": 212
    },
    {
      "feature_index": 281,
      "feature_name": "feature_281",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of multi-syllable words in the text\"\n    def syllable_count(word):\n        vowels = 'aeiouy'\n        return len([char for char in word if char in vowels])\n    \n    words = text.split()\n    multi_syllable_count = sum(1 for word in words if syllable_count(word) >= 3)\n    return float(multi_syllable_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009404591008182552,
        "mean_shap": -5.4513994215860516e-05,
        "std_shap": 0.0014095075898129259,
        "min_shap": -0.0030502276479402526,
        "max_shap": 0.007435766611841959
      },
      "rank": 213
    },
    {
      "feature_index": 255,
      "feature_name": "feature_255",
      "feature_code": "def feature(text: str) -> float:\n    'Average sentence length in characters'\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s) for s in sentences if s]\n    return float(statistics.mean(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009383167775657385,
        "mean_shap": 0.0002693416235514833,
        "std_shap": 0.0014016531510076043,
        "min_shap": -0.0071668328825640094,
        "max_shap": 0.004026761751586173
      },
      "rank": 214
    },
    {
      "feature_index": 118,
      "feature_name": "feature_118",
      "feature_code": "def feature(text: str) -> float:\n    'Sentence length variability measured as standard deviation'\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    return float(statistics.pstdev(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009373135495014043,
        "mean_shap": 0.00011546158503157982,
        "std_shap": 0.0011757919615636113,
        "min_shap": -0.004651275063307504,
        "max_shap": 0.0030037939930714777
      },
      "rank": 215
    },
    {
      "feature_index": 188,
      "feature_name": "feature_188",
      "feature_code": "def feature(text: str) -> float:\n    'Standard deviation of sentence lengths in words'\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    return float(statistics.pstdev(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009351218053306881,
        "mean_shap": 2.8940442192071317e-05,
        "std_shap": 0.0011360499548877156,
        "min_shap": -0.002574935814918943,
        "max_shap": 0.0038239808319398163
      },
      "rank": 216
    },
    {
      "feature_index": 305,
      "feature_name": "feature_305",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of total words to the number of unique words'\n    word_list = text.split()\n    return float(len(word_list)) / len(set(word_list)) if word_list else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009298740258548992,
        "mean_shap": 0.0003748521590701627,
        "std_shap": 0.0010740852471835807,
        "min_shap": -0.004394646473782739,
        "max_shap": 0.003601889577694844
      },
      "rank": 217
    },
    {
      "feature_index": 49,
      "feature_name": "feature_49",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of uppercase letters to total characters\"\n    uppercase_count = sum(1 for c in text if c.isupper())\n    total_count = len(text)\n    if total_count == 0:\n        return 0.0\n    return float(uppercase_count) / total_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009262198876688447,
        "mean_shap": -3.91690031771935e-05,
        "std_shap": 0.0010826717449855152,
        "min_shap": -0.002029559839629092,
        "max_shap": 0.0034037749500267587
      },
      "rank": 218
    },
    {
      "feature_index": 183,
      "feature_name": "feature_183",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of unique words to total words'\n    words = text.split()\n    unique_words = set(words)\n    return float(len(unique_words)) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009234178478562122,
        "mean_shap": 0.0002949583470845863,
        "std_shap": 0.0011121097386861537,
        "min_shap": -0.004086065822315759,
        "max_shap": 0.0024546762480971234
      },
      "rank": 219
    },
    {
      "feature_index": 162,
      "feature_name": "feature_162",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of multi-syllable words in the text\"\n    def syllable_count(word):\n        vowels = 'aeiouy'\n        return len([char for char in word if char in vowels])\n    \n    words = text.split()\n    multi_syllable_count = sum(1 for word in words if syllable_count(word) >= 3)\n    return float(multi_syllable_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009197030683797,
        "mean_shap": -0.00014606471841141207,
        "std_shap": 0.001270183474636111,
        "min_shap": -0.0051715385865707866,
        "max_shap": 0.004427939964488567
      },
      "rank": 220
    },
    {
      "feature_index": 358,
      "feature_name": "feature_358",
      "feature_code": "def feature(text: str) -> float:\n    'Average sentence length in characters'\n    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n    total_length = sum(len(s) for s in sentences)\n    return total_length / len(sentences) if sentences else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009110732791571734,
        "mean_shap": 5.5646360139873377e-05,
        "std_shap": 0.001244403602289391,
        "min_shap": -0.006050115031643899,
        "max_shap": 0.0025423261077570512
      },
      "rank": 221
    },
    {
      "feature_index": 95,
      "feature_name": "feature_95",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of sentence lengths in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    if len(lengths) < 2:\n        return 0.0\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009064591742728426,
        "mean_shap": 2.7442129566637446e-07,
        "std_shap": 0.001175676548291665,
        "min_shap": -0.004860364187048091,
        "max_shap": 0.002653729431135079
      },
      "rank": 222
    },
    {
      "feature_index": 355,
      "feature_name": "feature_355",
      "feature_code": "def feature(text: str) -> float:\n    'Count of specific thematic keywords related to children and family'\n    keywords = ['daughter', 'children', 'fun', 'party', 'tips', 'options']\n    return float(sum(text.lower().count(keyword) for keyword in keywords))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0009047656346343114,
        "mean_shap": 7.862786123967143e-05,
        "std_shap": 0.00144830374942589,
        "min_shap": -0.0009937496232332367,
        "max_shap": 0.00691291393376803
      },
      "rank": 223
    },
    {
      "feature_index": 171,
      "feature_name": "feature_171",
      "feature_code": "def feature(text: str) -> float:\n    'Frequency of the word \"I\" in the text'\n    count_i = text.lower().count('i')\n    return float(count_i)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008938842000132954,
        "mean_shap": 4.3534990977440925e-06,
        "std_shap": 0.00111089503464688,
        "min_shap": -0.004361978578255027,
        "max_shap": 0.0027284665457015076
      },
      "rank": 224
    },
    {
      "feature_index": 112,
      "feature_name": "feature_112",
      "feature_code": "def feature(text: str) -> float:\n    'Average sentence length in characters'\n    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n    total_length = sum(len(s) for s in sentences)\n    return total_length / len(sentences) if sentences else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008870001753153072,
        "mean_shap": 9.707927107531464e-05,
        "std_shap": 0.001202812809821188,
        "min_shap": -0.005706150090343929,
        "max_shap": 0.0025163372870854283
      },
      "rank": 225
    },
    {
      "feature_index": 152,
      "feature_name": "feature_152",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of total words to unique words\"\n    words = text.split()\n    unique_words = set(words)\n    return float(len(words)) / max(1, len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.000881977269827937,
        "mean_shap": 0.0002343768372003339,
        "std_shap": 0.0011232563873110164,
        "min_shap": -0.004228245757833706,
        "max_shap": 0.002533423021608267
      },
      "rank": 226
    },
    {
      "feature_index": 161,
      "feature_name": "feature_161",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of uppercase letters in the text\"\n    uppercase_count = sum(1 for c in text if c.isupper())\n    if len(text) == 0:\n        return 0.0\n    return float(uppercase_count) / len(text)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008666272985497652,
        "mean_shap": -8.507498806720212e-05,
        "std_shap": 0.0009940118900523959,
        "min_shap": -0.002192507492108468,
        "max_shap": 0.0022838629723233948
      },
      "rank": 227
    },
    {
      "feature_index": 93,
      "feature_name": "feature_93",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of first-person pronouns in the text\"\n    first_person_pronouns = ['I', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours']\n    count = sum(text.lower().count(pronoun.lower()) for pronoun in first_person_pronouns)\n    return float(count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008479779964584814,
        "mean_shap": 0.00012107806452239964,
        "std_shap": 0.0010556376866341132,
        "min_shap": -0.003387270528982481,
        "max_shap": 0.003977079269734145
      },
      "rank": 228
    },
    {
      "feature_index": 193,
      "feature_name": "feature_193",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of unique words to total words in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    unique_words = set(words)\n    return float(len(unique_words)) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008389316814098745,
        "mean_shap": 0.00016628301349930807,
        "std_shap": 0.0011237192003145126,
        "min_shap": -0.004872772140304455,
        "max_shap": 0.0019399955296191787
      },
      "rank": 229
    },
    {
      "feature_index": 333,
      "feature_name": "feature_333",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of sentence lengths in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    if not lengths:\n        return 0.0\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008365272156497076,
        "mean_shap": 8.099213335648577e-05,
        "std_shap": 0.0010496540692716448,
        "min_shap": -0.002528497776404391,
        "max_shap": 0.002842126998647354
      },
      "rank": 230
    },
    {
      "feature_index": 134,
      "feature_name": "feature_134",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of unique words to total words in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    unique_words = set(words)\n    return float(len(unique_words)) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008234517212843047,
        "mean_shap": 0.00021875814379994908,
        "std_shap": 0.001024881212377592,
        "min_shap": -0.0040291299689577155,
        "max_shap": 0.002836640636603409
      },
      "rank": 231
    },
    {
      "feature_index": 211,
      "feature_name": "feature_211",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of sentence lengths in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    return float(statistics.pstdev(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008231907224641161,
        "mean_shap": 9.862257479030267e-05,
        "std_shap": 0.0010227347362604343,
        "min_shap": -0.0025228772381140686,
        "max_shap": 0.0032859551511457926
      },
      "rank": 232
    },
    {
      "feature_index": 146,
      "feature_name": "feature_146",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of multi-syllable words in the text\"\n    def syllable_count(word):\n        vowels = 'aeiouy'\n        return len([char for char in word if char in vowels])\n    \n    words = text.split()\n    multi_syllable_count = sum(1 for word in words if syllable_count(word) >= 3)\n    return float(multi_syllable_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008162641896868346,
        "mean_shap": -0.0001857094813570712,
        "std_shap": 0.0011163306414622783,
        "min_shap": -0.0024631974850869817,
        "max_shap": 0.004520911974874926
      },
      "rank": 233
    },
    {
      "feature_index": 279,
      "feature_name": "feature_279",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    if upper_count == 0:\n        return float('inf') if lower_count > 0 else 0.0\n    return lower_count / upper_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008070239324874097,
        "mean_shap": 7.229568426572099e-05,
        "std_shap": 0.0009521924789742244,
        "min_shap": -0.0013740201379898738,
        "max_shap": 0.002677525262904562
      },
      "rank": 234
    },
    {
      "feature_index": 278,
      "feature_name": "feature_278",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of long words (greater than 7 characters) to total words'\n    words = text.split()\n    long_words = sum(1 for word in words if len(word) > 7)\n    return float(long_words) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0008040981303643824,
        "mean_shap": -0.00017391147670196323,
        "std_shap": 0.0011048179748689134,
        "min_shap": -0.0043142832860464655,
        "max_shap": 0.005498309952718115
      },
      "rank": 235
    },
    {
      "feature_index": 63,
      "feature_name": "feature_63",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of words that start with a capital letter\"\n    capitalized_count = sum(1 for word in text.split() if word[0].isupper())\n    return float(capitalized_count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007984268048718364,
        "mean_shap": 2.3444679960171323e-05,
        "std_shap": 0.0010439099253634764,
        "min_shap": -0.003191823733793646,
        "max_shap": 0.004898703987352974
      },
      "rank": 236
    },
    {
      "feature_index": 231,
      "feature_name": "feature_231",
      "feature_code": "def feature(text: str) -> float:\n    'Average syllable count per word in the text'\n    def syllable_count(word):\n        return max(1, sum(1 for char in word if char in 'aeiouAEIOU'))\n    \n    words = text.split()\n    if not words:\n        return 0.0\n    avg_syllables = sum(syllable_count(word) for word in words) / len(words)\n    return avg_syllables\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007984025244760723,
        "mean_shap": -3.813719984022316e-05,
        "std_shap": 0.0010026515017163991,
        "min_shap": -0.003339096504516969,
        "max_shap": 0.0024293374790021246
      },
      "rank": 237
    },
    {
      "feature_index": 168,
      "feature_name": "feature_168",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of uppercase letters to total letters'\n    uppercase_count = sum(1 for c in text if c.isupper())\n    total_letters = sum(1 for c in text if c.isalpha())\n    if total_letters == 0:\n        return 0.0\n    return float(uppercase_count) / total_letters\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007939605296923391,
        "mean_shap": 3.3975227061095504e-05,
        "std_shap": 0.0009524138385563694,
        "min_shap": -0.0017502024902604646,
        "max_shap": 0.002465884324441317
      },
      "rank": 238
    },
    {
      "feature_index": 165,
      "feature_name": "feature_165",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of unique words to total words in the text\"\n    words = text.split()\n    unique_words = set(words)\n    if len(words) == 0:\n        return 0.0\n    return float(len(unique_words)) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007930785312371483,
        "mean_shap": 0.00022837370067858205,
        "std_shap": 0.001018317069082159,
        "min_shap": -0.0040287688406705656,
        "max_shap": 0.00181458133593416
      },
      "rank": 239
    },
    {
      "feature_index": 276,
      "feature_name": "feature_276",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of technical terms or jargon in the text\"\n    technical_terms_pattern = r'\\b(?:fertilizer|roller blade|AC/DC|environmental|policy|dishes|information|plants)\\b'\n    technical_terms = re.findall(technical_terms_pattern, text, re.IGNORECASE)\n    return float(len(technical_terms))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007875207556874732,
        "mean_shap": 0.00037322994666131524,
        "std_shap": 0.0014708501364255845,
        "min_shap": -0.013940441361855386,
        "max_shap": 0.0035362078430125816
      },
      "rank": 240
    },
    {
      "feature_index": 58,
      "feature_name": "feature_58",
      "feature_code": "def feature(text: str) -> float:\n    \"Average sentence length measured in characters\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s) for s in sentences if s.strip()]\n    if not lengths:\n        return 0.0\n    return float(statistics.mean(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007771983695648416,
        "mean_shap": 0.00026133041947586517,
        "std_shap": 0.0011612891450227779,
        "min_shap": -0.005071601399579941,
        "max_shap": 0.004149777707021285
      },
      "rank": 241
    },
    {
      "feature_index": 209,
      "feature_name": "feature_209",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of sentence lengths measured in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    if not lengths:\n        return 0.0\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.000775363747865639,
        "mean_shap": 0.00013863732311213435,
        "std_shap": 0.0009358344394170408,
        "min_shap": -0.002245454062300767,
        "max_shap": 0.0024241870956093507
      },
      "rank": 242
    },
    {
      "feature_index": 0,
      "feature_name": "feature_0",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique bi-grams in the text\"\n    words = text.split()\n    bi_grams = set((words[i], words[i + 1]) for i in range(len(words) - 1))\n    return float(len(bi_grams))\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007730399368561456,
        "mean_shap": -6.15264773491814e-05,
        "std_shap": 0.0009766446759237786,
        "min_shap": -0.0013758229435327245,
        "max_shap": 0.0036415474481014992
      },
      "rank": 243
    },
    {
      "feature_index": 219,
      "feature_name": "feature_219",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    words = set(text.split())\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words) / len(words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007699717149733123,
        "mean_shap": 0.00012170351002508248,
        "std_shap": 0.0009880312666078386,
        "min_shap": -0.0036552533798914284,
        "max_shap": 0.0031232691546541607
      },
      "rank": 244
    },
    {
      "feature_index": 33,
      "feature_name": "feature_33",
      "feature_code": "def feature(text: str) -> float:\n    \"Average length of unique words in the text\"\n    words = set(text.split())\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words)) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007690647146374564,
        "mean_shap": 6.804263762206758e-05,
        "std_shap": 0.000978728684163173,
        "min_shap": -0.003319713905816897,
        "max_shap": 0.002918749626774338
      },
      "rank": 245
    },
    {
      "feature_index": 115,
      "feature_name": "feature_115",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words)) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007522260551634517,
        "mean_shap": 2.165885331080533e-05,
        "std_shap": 0.0009752662181454093,
        "min_shap": -0.003599757363415921,
        "max_shap": 0.002933669995089892
      },
      "rank": 246
    },
    {
      "feature_index": 280,
      "feature_name": "feature_280",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of technical terms or jargon in the text\"\n    technical_terms_pattern = r'\\b(?:fertilizer|roller blade|AC/DC|environmental|policy|dishes|information|plants)\\b'\n    technical_terms = re.findall(technical_terms_pattern, text, re.IGNORECASE)\n    return float(len(technical_terms))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007423405974219227,
        "mean_shap": 0.0003870518825061723,
        "std_shap": 0.0013322625470610753,
        "min_shap": -0.010773624097672546,
        "max_shap": 0.0036504813037423795
      },
      "rank": 247
    },
    {
      "feature_index": 306,
      "feature_name": "feature_306",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words)) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007353209936834204,
        "mean_shap": 4.760501076303289e-05,
        "std_shap": 0.0009773903190080362,
        "min_shap": -0.002374299576715449,
        "max_shap": 0.0028621389492058894
      },
      "rank": 248
    },
    {
      "feature_index": 125,
      "feature_name": "feature_125",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique bi-grams in the text\"\n    words = text.split()\n    bi_grams = set(zip(words, words[1:]))\n    return float(len(bi_grams))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007302547771581418,
        "mean_shap": -5.180581255979696e-05,
        "std_shap": 0.0010581326977219833,
        "min_shap": -0.0022778770031277205,
        "max_shap": 0.0040450865558222
      },
      "rank": 249
    },
    {
      "feature_index": 164,
      "feature_name": "feature_164",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of syllables per word\"\n    def syllable_count(word):\n        return len(re.findall(r'[aeiouy]{1,2}', word.lower())) or 1\n\n    words = text.split()\n    total_syllables = sum(syllable_count(word) for word in words)\n    return float(total_syllables) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007248837146344404,
        "mean_shap": 0.00012580461264539812,
        "std_shap": 0.0009232499118038785,
        "min_shap": -0.002534502431725997,
        "max_shap": 0.0032050330438387854
      },
      "rank": 250
    },
    {
      "feature_index": 237,
      "feature_name": "feature_237",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of unique words to total words'\n    words = text.split()\n    unique_words = set(words)\n    return float(len(unique_words)) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007221058013796963,
        "mean_shap": 0.0002004818501894077,
        "std_shap": 0.0009420457319759095,
        "min_shap": -0.004257927557625504,
        "max_shap": 0.0019297117544367442
      },
      "rank": 251
    },
    {
      "feature_index": 12,
      "feature_name": "feature_12",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words)) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007192030906156907,
        "mean_shap": 6.631965571122757e-05,
        "std_shap": 0.0009261362028188458,
        "min_shap": -0.003029176466444464,
        "max_shap": 0.0020240687007503293
      },
      "rank": 252
    },
    {
      "feature_index": 17,
      "feature_name": "feature_17",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    if upper_count == 0:\n        return 0.0\n    return lower_count / upper_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007156303135110888,
        "mean_shap": 1.3623119533008723e-05,
        "std_shap": 0.0008576532904909367,
        "min_shap": -0.0018170492870688518,
        "max_shap": 0.002581908066062735
      },
      "rank": 253
    },
    {
      "feature_index": 52,
      "feature_name": "feature_52",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    if upper_count == 0:\n        return 0.0\n    return lower_count / upper_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.000715215671820119,
        "mean_shap": -2.3721732400392672e-05,
        "std_shap": 0.0008758104638065964,
        "min_shap": -0.002549464146095929,
        "max_shap": 0.002697961447474388
      },
      "rank": 254
    },
    {
      "feature_index": 245,
      "feature_name": "feature_245",
      "feature_code": "def feature(text: str) -> float:\n    \"Total count of conjunctions in the text\"\n    conjunctions = ['and', 'but', 'or', 'nor', 'for', 'so', 'yet']\n    count = sum(text.lower().count(conj) for conj in conjunctions)\n    return float(count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007105955028973279,
        "mean_shap": -8.20936796143192e-05,
        "std_shap": 0.0008539288727702547,
        "min_shap": -0.0034617894221078997,
        "max_shap": 0.0017123572200100313
      },
      "rank": 255
    },
    {
      "feature_index": 337,
      "feature_name": "feature_337",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words)) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007073144621379457,
        "mean_shap": 3.5411897744757396e-05,
        "std_shap": 0.0008939278527441961,
        "min_shap": -0.002649502212148367,
        "max_shap": 0.002252298469032625
      },
      "rank": 256
    },
    {
      "feature_index": 247,
      "feature_name": "feature_247",
      "feature_code": "def feature(text: str) -> float:\n    'Average character length of unique words in the text'\n    words = set(text.split())\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words)) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0007069386090976069,
        "mean_shap": -2.3488668728595898e-05,
        "std_shap": 0.0009566686375772096,
        "min_shap": -0.002203122106789391,
        "max_shap": 0.0027610218235505886
      },
      "rank": 257
    },
    {
      "feature_index": 266,
      "feature_name": "feature_266",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters in the text\"\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    if upper_count == 0:\n        return 0.0\n    return lower_count / upper_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006985304663884954,
        "mean_shap": 3.801242817372626e-05,
        "std_shap": 0.000817270874032449,
        "min_shap": -0.001750211386799842,
        "max_shap": 0.002119392249916712
      },
      "rank": 258
    },
    {
      "feature_index": 322,
      "feature_name": "feature_322",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return sum(len(word) for word in unique_words) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006984049557167312,
        "mean_shap": 6.568347881582159e-05,
        "std_shap": 0.0009497172026186941,
        "min_shap": -0.002460996482194412,
        "max_shap": 0.0028159454258379945
      },
      "rank": 259
    },
    {
      "feature_index": 243,
      "feature_name": "feature_243",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of lower to upper case letters in the text'\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    return lower_count / upper_count if upper_count > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006959867293008213,
        "mean_shap": 4.435779768277315e-05,
        "std_shap": 0.0008707802258396351,
        "min_shap": -0.0013312164373297916,
        "max_shap": 0.00232238705494234
      },
      "rank": 260
    },
    {
      "feature_index": 202,
      "feature_name": "feature_202",
      "feature_code": "def feature(text: str) -> float:\n    'Count of conjunctions in the text'\n    conjunctions = ['and', 'but', 'or', 'so', 'for', 'nor', 'yet']\n    conjunction_count = sum(text.lower().count(conj) for conj in conjunctions)\n    return float(conjunction_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006886113959181982,
        "mean_shap": -1.6232195351503467e-05,
        "std_shap": 0.0007696917945477437,
        "min_shap": -0.0018191270339037917,
        "max_shap": 0.0014462889143748228
      },
      "rank": 261
    },
    {
      "feature_index": 226,
      "feature_name": "feature_226",
      "feature_code": "def feature(text: str) -> float:\n    'Standard deviation of word lengths in the text'\n    word_lengths = [len(word) for word in text.split()]\n    if not word_lengths:\n        return 0.0\n    return float(statistics.pstdev(word_lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006868384592661088,
        "mean_shap": 4.09190189099964e-05,
        "std_shap": 0.0010703794048008155,
        "min_shap": -0.005432330828633531,
        "max_shap": 0.0021442298326044113
      },
      "rank": 262
    },
    {
      "feature_index": 311,
      "feature_name": "feature_311",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of unique words to total words in the text\"\n    words = text.split()\n    unique_words = set(words)\n    if not words:\n        return 0.0\n    return float(len(unique_words)) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006834185600597107,
        "mean_shap": 0.00017344389729247596,
        "std_shap": 0.0008993137054892814,
        "min_shap": -0.003789904142130297,
        "max_shap": 0.0021338793659984264
      },
      "rank": 263
    },
    {
      "feature_index": 217,
      "feature_name": "feature_217",
      "feature_code": "def feature(text: str) -> float:\n    'Average word length considering only unique words'\n    unique_words = set(text.split())\n    average_length = sum(len(word) for word in unique_words) / len(unique_words) if unique_words else 0.0\n    return float(average_length)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006719766903292571,
        "mean_shap": 1.2371751783438954e-05,
        "std_shap": 0.000930082297425188,
        "min_shap": -0.0037801753749866058,
        "max_shap": 0.0036040878923834477
      },
      "rank": 264
    },
    {
      "feature_index": 108,
      "feature_name": "feature_108",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of technical terms or jargon in the text\"\n    technical_terms_pattern = r'\\b(?:fertilizer|roller blade|AC/DC|environmental|policy|dishes|information|plants)\\b'\n    technical_terms = re.findall(technical_terms_pattern, text, re.IGNORECASE)\n    return float(len(technical_terms))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006662650898279414,
        "mean_shap": 0.0003408606884511217,
        "std_shap": 0.0011912670754186101,
        "min_shap": -0.009348995355196843,
        "max_shap": 0.0030408967772262824
      },
      "rank": 265
    },
    {
      "feature_index": 229,
      "feature_name": "feature_229",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006657426430594167,
        "mean_shap": 8.933224585476807e-05,
        "std_shap": 0.0009616290991480884,
        "min_shap": -0.004824847901821194,
        "max_shap": 0.0027187191246498023
      },
      "rank": 266
    },
    {
      "feature_index": 325,
      "feature_name": "feature_325",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of punctuation to total characters in the text'\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    return punctuation_count / (len(text) + 1)  # Add 1 to avoid division by zero\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006641870378514406,
        "mean_shap": -6.016600765422172e-06,
        "std_shap": 0.000983628899561467,
        "min_shap": -0.004676192584419451,
        "max_shap": 0.002499493677770981
      },
      "rank": 267
    },
    {
      "feature_index": 2,
      "feature_name": "feature_2",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique bi-grams in the text\"\n    words = text.split()\n    bi_grams = set((words[i], words[i+1]) for i in range(len(words)-1))\n    return float(len(bi_grams))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00066236254560452,
        "mean_shap": -1.7953985380218847e-05,
        "std_shap": 0.0009270151319046033,
        "min_shap": -0.0017044711075501946,
        "max_shap": 0.003572503838104354
      },
      "rank": 268
    },
    {
      "feature_index": 135,
      "feature_name": "feature_135",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters in the text\"\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    if upper_count == 0:\n        return 0.0\n    return lower_count / upper_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006583523133650832,
        "mean_shap": -2.9782133267695352e-05,
        "std_shap": 0.0007891136681955999,
        "min_shap": -0.0016070173170344756,
        "max_shap": 0.002773341936574454
      },
      "rank": 269
    },
    {
      "feature_index": 116,
      "feature_name": "feature_116",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    word_lengths = [len(word) for word in words]\n    if not word_lengths:\n        return 0.0\n    return float(statistics.pstdev(word_lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006394565362921986,
        "mean_shap": 6.47827681671275e-05,
        "std_shap": 0.0012588790938357342,
        "min_shap": -0.0101767571851719,
        "max_shap": 0.0013287629226938146
      },
      "rank": 270
    },
    {
      "feature_index": 149,
      "feature_name": "feature_149",
      "feature_code": "def feature(text: str) -> float:\n    'Variance in word lengths in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    mean_length = statistics.mean(lengths)\n    variance = statistics.pstdev(lengths)\n    return float(variance)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006338959103204301,
        "mean_shap": 8.590892359395295e-05,
        "std_shap": 0.0009936609042515763,
        "min_shap": -0.0064794275632825615,
        "max_shap": 0.0017848167679203554
      },
      "rank": 271
    },
    {
      "feature_index": 304,
      "feature_name": "feature_304",
      "feature_code": "def feature(text: str) -> float:\n    'Average sentence length measured in characters'\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s) for s in sentences if s.strip()]\n    return float(statistics.mean(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006276163312008145,
        "mean_shap": 0.00018280169376280774,
        "std_shap": 0.0009511786184603552,
        "min_shap": -0.004421909026418263,
        "max_shap": 0.004138098882517201
      },
      "rank": 272
    },
    {
      "feature_index": 104,
      "feature_name": "feature_104",
      "feature_code": "def feature(text: str) -> float:\n    \"Punctuation richness measured by unique punctuation marks\"\n    punctuation_set = set(c for c in text if not c.isalnum() and not c.isspace())\n    return float(len(punctuation_set))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006201728227644922,
        "mean_shap": 0.000126338873463693,
        "std_shap": 0.0008763899089636142,
        "min_shap": -0.0038204941431362258,
        "max_shap": 0.0016173371719575371
      },
      "rank": 273
    },
    {
      "feature_index": 346,
      "feature_name": "feature_346",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters in the text\"\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    if upper_count == 0:  # Avoid division by zero\n        return 0.0\n    return lower_count / upper_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.000613563750399961,
        "mean_shap": 2.3537989445959158e-05,
        "std_shap": 0.0007375007587807116,
        "min_shap": -0.0015144104392376624,
        "max_shap": 0.0023258879953403353
      },
      "rank": 274
    },
    {
      "feature_index": 339,
      "feature_name": "feature_339",
      "feature_code": "def feature(text: str) -> float:\n    'Count of conjunctions used in the text'\n    conjunctions = {'and', 'but', 'or', 'nor', 'for', 'so', 'yet'}\n    return float(sum(text.lower().count(conj) for conj in conjunctions))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006102193502827605,
        "mean_shap": 2.9292302655818017e-05,
        "std_shap": 0.0007341968619249942,
        "min_shap": -0.0033994180357803778,
        "max_shap": 0.0022479176053488794
      },
      "rank": 275
    },
    {
      "feature_index": 11,
      "feature_name": "feature_11",
      "feature_code": "def feature(text: str) -> float:\n    'Count of unique bi-grams in the text'\n    words = text.split()\n    bi_grams = set(zip(words, words[1:]))\n    return float(len(bi_grams))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006075012249126934,
        "mean_shap": -9.508683877485692e-05,
        "std_shap": 0.0007280548435829946,
        "min_shap": -0.0021174727205151666,
        "max_shap": 0.0015168825657489449
      },
      "rank": 276
    },
    {
      "feature_index": 39,
      "feature_name": "feature_39",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique bi-grams in the text\"\n    words = text.split()\n    bi_grams = set((words[i], words[i+1]) for i in range(len(words) - 1))\n    return float(len(bi_grams))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0006026555727167341,
        "mean_shap": -1.0385553374563403e-05,
        "std_shap": 0.0007782167356874923,
        "min_shap": -0.0013623499814064835,
        "max_shap": 0.0024871228799559827
      },
      "rank": 277
    },
    {
      "feature_index": 45,
      "feature_name": "feature_45",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words)) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005985431064370402,
        "mean_shap": -2.5535610376715303e-06,
        "std_shap": 0.0008956506567996747,
        "min_shap": -0.0036697531741352583,
        "max_shap": 0.004221231291127128
      },
      "rank": 278
    },
    {
      "feature_index": 174,
      "feature_name": "feature_174",
      "feature_code": "def feature(text: str) -> float:\n    'Average word length considering only unique words in the text'\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words)) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005933440815459155,
        "mean_shap": 2.8573453705412174e-05,
        "std_shap": 0.0008076104458642817,
        "min_shap": -0.0024935242836547954,
        "max_shap": 0.0027920342665417896
      },
      "rank": 279
    },
    {
      "feature_index": 24,
      "feature_name": "feature_24",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths)) if len(lengths) > 1 else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005846806252493232,
        "mean_shap": 0.0001116405315214681,
        "std_shap": 0.000915508754448423,
        "min_shap": -0.005371864684410844,
        "max_shap": 0.00290284069401243
      },
      "rank": 280
    },
    {
      "feature_index": 65,
      "feature_name": "feature_65",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique bi-grams in the text\"\n    words = text.split()\n    bi_grams = set(zip(words, words[1:]))\n    return float(len(bi_grams))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005835556588201857,
        "mean_shap": 1.538552080326525e-05,
        "std_shap": 0.0008031548889152813,
        "min_shap": -0.001658260117083789,
        "max_shap": 0.0027014969913334084
      },
      "rank": 281
    },
    {
      "feature_index": 246,
      "feature_name": "feature_246",
      "feature_code": "def feature(text: str) -> float:\n    \"Total count of punctuation marks in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    return float(punctuation_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005811677656867098,
        "mean_shap": 3.984656790015527e-05,
        "std_shap": 0.000775538334023097,
        "min_shap": -0.0029429988188013814,
        "max_shap": 0.0019512142743515451
      },
      "rank": 282
    },
    {
      "feature_index": 344,
      "feature_name": "feature_344",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation characters to total characters\"\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    if len(text) == 0:\n        return 0.0\n    return float(punctuation_count / len(text))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005762858329373799,
        "mean_shap": 5.198515309834161e-05,
        "std_shap": 0.0008334278203203869,
        "min_shap": -0.0036527878485344764,
        "max_shap": 0.0029558984113349025
      },
      "rank": 283
    },
    {
      "feature_index": 155,
      "feature_name": "feature_155",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words)) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005753676377010861,
        "mean_shap": 3.837345526161056e-05,
        "std_shap": 0.0007894974984871776,
        "min_shap": -0.0025694454246380886,
        "max_shap": 0.002381432016803384
      },
      "rank": 284
    },
    {
      "feature_index": 260,
      "feature_name": "feature_260",
      "feature_code": "def feature(text: str) -> float:\n    'Standard deviation of word lengths in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths)) if len(lengths) > 1 else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005721827968483234,
        "mean_shap": 7.667771466505875e-05,
        "std_shap": 0.0009315278438912046,
        "min_shap": -0.006113217695981811,
        "max_shap": 0.0015016689866855285
      },
      "rank": 285
    },
    {
      "feature_index": 300,
      "feature_name": "feature_300",
      "feature_code": "def feature(text: str) -> float:\n    'Average word length considering only unique words'\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words) / len(unique_words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005684654363467202,
        "mean_shap": -5.008997184114453e-05,
        "std_shap": 0.0008466481449463189,
        "min_shap": -0.0039054886821563773,
        "max_shap": 0.0027515093875707746
      },
      "rank": 286
    },
    {
      "feature_index": 365,
      "feature_name": "feature_365",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005664798226708118,
        "mean_shap": 6.809123455083238e-05,
        "std_shap": 0.0009967721569671562,
        "min_shap": -0.007203282258135629,
        "max_shap": 0.0014076042978903502
      },
      "rank": 287
    },
    {
      "feature_index": 313,
      "feature_name": "feature_313",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths)) if len(lengths) > 1 else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005628312593672956,
        "mean_shap": 7.716715837545116e-05,
        "std_shap": 0.0009578815227064279,
        "min_shap": -0.00575547882567775,
        "max_shap": 0.0016810900387059337
      },
      "rank": 288
    },
    {
      "feature_index": 198,
      "feature_name": "feature_198",
      "feature_code": "def feature(text: str) -> float:\n    \"Punctuation richness measured by unique punctuation marks\"\n    punctuation_set = set(c for c in text if not c.isalnum() and not c.isspace())\n    return float(len(punctuation_set))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005624964116244734,
        "mean_shap": 0.00015696587498430963,
        "std_shap": 0.0007566550796351242,
        "min_shap": -0.0032486101554247927,
        "max_shap": 0.0018154473133031265
      },
      "rank": 289
    },
    {
      "feature_index": 170,
      "feature_name": "feature_170",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of lowercase to uppercase letters\"\n    lower_count = sum(1 for c in text if c.islower())\n    upper_count = sum(1 for c in text if c.isupper())\n    if upper_count == 0:\n        return float(lower_count)  # Return lower count if no uppercase letters\n    return float(lower_count) / upper_count\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005592737939909754,
        "mean_shap": -3.596859264177879e-05,
        "std_shap": 0.0006787422274733298,
        "min_shap": -0.0012499741733190447,
        "max_shap": 0.002223334570655747
      },
      "rank": 290
    },
    {
      "feature_index": 203,
      "feature_name": "feature_203",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of unique punctuation characters used\"\n    punctuations = set(c for c in text if not c.isalnum() and not c.isspace())\n    return float(len(punctuations))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005525421226998803,
        "mean_shap": 0.00013091894178603373,
        "std_shap": 0.0007363431554802963,
        "min_shap": -0.0032513817834561244,
        "max_shap": 0.0014735599753559962
      },
      "rank": 291
    },
    {
      "feature_index": 73,
      "feature_name": "feature_73",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of multi-syllable words in the text\"\n    def syllable_count(word):\n        vowels = 'aeiouy'\n        return len([char for char in word if char in vowels])\n    \n    words = text.split()\n    multi_syllable_count = sum(1 for word in words if syllable_count(word) >= 3)\n    return float(multi_syllable_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005514034669868413,
        "mean_shap": -0.00028224531144589775,
        "std_shap": 0.0006804963934543786,
        "min_shap": -0.0017436686033246932,
        "max_shap": 0.0030556082462372034
      },
      "rank": 292
    },
    {
      "feature_index": 105,
      "feature_name": "feature_105",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of multi-syllable words in the text\"\n    def syllable_count(word):\n        vowels = 'aeiouy'\n        return len([char for char in word if char in vowels])\n    \n    words = text.split()\n    multi_syllable_count = sum(1 for word in words if syllable_count(word) >= 3)\n    return float(multi_syllable_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005489652411896822,
        "mean_shap": -0.00014116651227900274,
        "std_shap": 0.0007108819010135826,
        "min_shap": -0.0019709850738524153,
        "max_shap": 0.0029944656043922476
      },
      "rank": 293
    },
    {
      "feature_index": 234,
      "feature_name": "feature_234",
      "feature_code": "def feature(text: str) -> float:\n    \"Total count of conjunctions in the text\"\n    conjunctions = ['and', 'but', 'or', 'nor', 'for', 'so', 'yet']\n    count = sum(text.lower().count(conj) for conj in conjunctions)\n    return float(count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005444392736764211,
        "mean_shap": -7.335479706581522e-05,
        "std_shap": 0.0006554040731027155,
        "min_shap": -0.0020322157163170924,
        "max_shap": 0.002232731279180962
      },
      "rank": 294
    },
    {
      "feature_index": 252,
      "feature_name": "feature_252",
      "feature_code": "def feature(text: str) -> float:\n    'Standard deviation of word lengths in the text'\n    word_lengths = [len(word) for word in text.split()]\n    if not word_lengths:\n        return 0.0\n    return float(statistics.pstdev(word_lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005400757769397562,
        "mean_shap": 9.415829990741866e-05,
        "std_shap": 0.0009432866116417517,
        "min_shap": -0.006725441389603414,
        "max_shap": 0.0019558948538364713
      },
      "rank": 295
    },
    {
      "feature_index": 78,
      "feature_name": "feature_78",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of numeric tokens to total tokens in the text'\n    words = text.split()\n    numeric_count = sum(1 for word in words if word.isdigit())\n    return float(numeric_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005321134098015779,
        "mean_shap": 6.758108772704547e-05,
        "std_shap": 0.0010590104713868312,
        "min_shap": -0.001111053281948258,
        "max_shap": 0.005746968806168654
      },
      "rank": 296
    },
    {
      "feature_index": 126,
      "feature_name": "feature_126",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of conjunctions used in the text\"\n    conjunctions = ['and', 'but', 'or', 'so', 'for', 'nor', 'yet']\n    conjunction_count = sum(text.lower().count(conj) for conj in conjunctions)\n    return float(conjunction_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005232297947856177,
        "mean_shap": -3.287330668148749e-05,
        "std_shap": 0.0006550259443268083,
        "min_shap": -0.0030849617416972707,
        "max_shap": 0.0012785628948028221
      },
      "rank": 297
    },
    {
      "feature_index": 140,
      "feature_name": "feature_140",
      "feature_code": "def feature(text: str) -> float:\n    \"Total number of distinct punctuation marks used in the text\"\n    punctuation_set = set(c for c in text if not c.isalnum() and not c.isspace())\n    return float(len(punctuation_set))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005226100424985567,
        "mean_shap": 8.144414203290547e-05,
        "std_shap": 0.0007070632403732869,
        "min_shap": -0.003057660616138664,
        "max_shap": 0.0019605930938610106
      },
      "rank": 298
    },
    {
      "feature_index": 173,
      "feature_name": "feature_173",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of uppercase to total letters in the text'\n    total_letters = sum(1 for c in text if c.isalpha())\n    uppercase_letters = sum(1 for c in text if c.isupper())\n    return (uppercase_letters / total_letters) if total_letters > 0 else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005124773379950502,
        "mean_shap": -5.6313465338904e-06,
        "std_shap": 0.0006166298590301002,
        "min_shap": -0.001036146207623355,
        "max_shap": 0.0022117232115655616
      },
      "rank": 299
    },
    {
      "feature_index": 34,
      "feature_name": "feature_34",
      "feature_code": "def feature(text: str) -> float:\n    \"Average sentence length in characters\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s) for s in sentences if s]\n    if not lengths:\n        return 0.0\n    return float(statistics.mean(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005081591966734197,
        "mean_shap": 0.0001774067112074985,
        "std_shap": 0.0007454817502755884,
        "min_shap": -0.0034988261873681336,
        "max_shap": 0.001922993282250006
      },
      "rank": 300
    },
    {
      "feature_index": 123,
      "feature_name": "feature_123",
      "feature_code": "def feature(text: str) -> float:\n    'Average number of syllables per word in the text'\n    def count_syllables(word):\n        return len(re.findall(r'[aeiouy]+', word.lower())) or 1\n    words = text.split()\n    if not words:\n        return 0.0\n    syllable_count = sum(count_syllables(word) for word in words)\n    return float(syllable_count) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005074646249889306,
        "mean_shap": -3.123275667326259e-06,
        "std_shap": 0.0006698298223209397,
        "min_shap": -0.002597999347659615,
        "max_shap": 0.002581545663918045
      },
      "rank": 301
    },
    {
      "feature_index": 21,
      "feature_name": "feature_21",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0005025572939310488,
        "mean_shap": 6.731380269683287e-05,
        "std_shap": 0.0007301936630667278,
        "min_shap": -0.003265039895383483,
        "max_shap": 0.0016141531306728763
      },
      "rank": 302
    },
    {
      "feature_index": 8,
      "feature_name": "feature_8",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0004979149369699122,
        "mean_shap": 6.217964508137977e-05,
        "std_shap": 0.0008309849291230726,
        "min_shap": -0.0052556251759567135,
        "max_shap": 0.0014670671976569436
      },
      "rank": 303
    },
    {
      "feature_index": 145,
      "feature_name": "feature_145",
      "feature_code": "def feature(text: str) -> float:\n    'Ratio of numeric values to total words in the text'\n    words = text.split()\n    numeric_count = sum(1 for word in words if word.isdigit())\n    return float(numeric_count) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0004956972467430186,
        "mean_shap": 7.284608989909456e-05,
        "std_shap": 0.000979500061437394,
        "min_shap": -0.0007981179278467388,
        "max_shap": 0.005880903959616986
      },
      "rank": 304
    },
    {
      "feature_index": 83,
      "feature_name": "feature_83",
      "feature_code": "def feature(text: str) -> float:\n    \"Ratio of punctuation characters to total characters\"\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    if len(text) == 0:\n        return 0.0\n    return float(punctuation_count / len(text))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.000494405704862706,
        "mean_shap": -5.5581209847790656e-05,
        "std_shap": 0.0007745235215027719,
        "min_shap": -0.005023323102455463,
        "max_shap": 0.001754220534720357
      },
      "rank": 305
    },
    {
      "feature_index": 72,
      "feature_name": "feature_72",
      "feature_code": "def feature(text: str) -> float:\n    \"Punctuation richness measured by unique punctuation marks\"\n    punctuation_set = set(c for c in text if not c.isalnum() and not c.isspace())\n    return float(len(punctuation_set))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00048620066005540763,
        "mean_shap": 0.00010365173016575,
        "std_shap": 0.0007041239288269074,
        "min_shap": -0.002877673972540785,
        "max_shap": 0.0017468239781280306
      },
      "rank": 306
    },
    {
      "feature_index": 291,
      "feature_name": "feature_291",
      "feature_code": "def feature(text: str) -> float:\n    'Standard deviation of word lengths in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00048305972826800985,
        "mean_shap": 8.614009097671386e-05,
        "std_shap": 0.0007097065209425524,
        "min_shap": -0.004534192176407529,
        "max_shap": 0.0014459817712281545
      },
      "rank": 307
    },
    {
      "feature_index": 351,
      "feature_name": "feature_351",
      "feature_code": "def feature(text: str) -> float:\n    'Count of the word \"you\" in the text'\n    return float(text.lower().count('you'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00048046310263486907,
        "mean_shap": -2.9654331363535177e-05,
        "std_shap": 0.0010095266118069497,
        "min_shap": -0.0042644206612376025,
        "max_shap": 0.005928513760971993
      },
      "rank": 308
    },
    {
      "feature_index": 354,
      "feature_name": "feature_354",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of punctuation to total characters in the text'\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    return punctuation_count / (len(text) + 1)  # Add 1 to avoid division by zero\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00047776058636128617,
        "mean_shap": -2.8862175390151766e-05,
        "std_shap": 0.0007036030020881465,
        "min_shap": -0.004151729069069426,
        "max_shap": 0.0014052114905912687
      },
      "rank": 309
    },
    {
      "feature_index": 274,
      "feature_name": "feature_274",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of the lengths of words in the text\"\n    words = text.split()\n    lengths = [len(word) for word in words]\n    if not lengths:\n        return 0.0\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00047452316009953256,
        "mean_shap": 5.134980329857079e-05,
        "std_shap": 0.0008906945251227303,
        "min_shap": -0.006522098518436832,
        "max_shap": 0.0014423817408930927
      },
      "rank": 310
    },
    {
      "feature_index": 250,
      "feature_name": "feature_250",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    word_lengths = [len(word) for word in words]\n    return float(statistics.pstdev(word_lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00046722285014343194,
        "mean_shap": 8.673919090119027e-05,
        "std_shap": 0.0006712787102642638,
        "min_shap": -0.0029832204547079817,
        "max_shap": 0.001966885560025174
      },
      "rank": 311
    },
    {
      "feature_index": 321,
      "feature_name": "feature_321",
      "feature_code": "def feature(text: str) -> float:\n    \"Total count of conjunctions in the text\"\n    conjunctions = ['and', 'but', 'or', 'nor', 'for', 'so', 'yet']\n    count = sum(text.lower().count(conj) for conj in conjunctions)\n    return float(count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0004617292938734506,
        "mean_shap": -8.633933364963251e-05,
        "std_shap": 0.0005571405690026505,
        "min_shap": -0.001489666282172006,
        "max_shap": 0.0012188858413414432
      },
      "rank": 312
    },
    {
      "feature_index": 359,
      "feature_name": "feature_359",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of times the word 'you' appears in the text\"\n    return float(text.lower().count('you'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00045612118710536184,
        "mean_shap": -6.461563490303771e-05,
        "std_shap": 0.0008877167876409578,
        "min_shap": -0.004020645738458268,
        "max_shap": 0.005092432340532009
      },
      "rank": 313
    },
    {
      "feature_index": 16,
      "feature_name": "feature_16",
      "feature_code": "def feature(text: str) -> float:\n    'Standard deviation of word lengths in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    return float(statistics.pstdev(lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0004541707824837536,
        "mean_shap": 0.00010556722918052868,
        "std_shap": 0.0008403936172294847,
        "min_shap": -0.0075600020772184995,
        "max_shap": 0.0013335708366522259
      },
      "rank": 314
    },
    {
      "feature_index": 107,
      "feature_name": "feature_107",
      "feature_code": "def feature(text: str) -> float:\n    'Proportion of punctuation to total characters in the text'\n    total_chars = len(text)\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    if total_chars == 0:\n        return 0.0\n    return punctuation_count / total_chars\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00045196800119590044,
        "mean_shap": -1.2245284293071593e-05,
        "std_shap": 0.0006815364383232662,
        "min_shap": -0.003429574618039833,
        "max_shap": 0.0014855420127669334
      },
      "rank": 315
    },
    {
      "feature_index": 177,
      "feature_name": "feature_177",
      "feature_code": "def feature(text: str) -> float:\n    \"Proportion of punctuation characters in the text\"\n    punctuation_count = sum(1 for c in text if c in string.punctuation)\n    return punctuation_count / max(len(text), 1)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00044932180872016796,
        "mean_shap": -4.44572788400773e-05,
        "std_shap": 0.0006697807469369337,
        "min_shap": -0.0039101507205764425,
        "max_shap": 0.0015565678393758458
      },
      "rank": 316
    },
    {
      "feature_index": 157,
      "feature_name": "feature_157",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of times the word 'you' appears in the text\"\n    return float(text.lower().count('you'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00044891249774002713,
        "mean_shap": -5.194171564257864e-05,
        "std_shap": 0.0008713734323473816,
        "min_shap": -0.003281853161010749,
        "max_shap": 0.005207829460723724
      },
      "rank": 317
    },
    {
      "feature_index": 363,
      "feature_name": "feature_363",
      "feature_code": "def feature(text: str) -> float:\n    'Standard deviation of the lengths of words in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    word_lengths = [len(word) for word in words]\n    return float(statistics.pstdev(word_lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00044835647882801165,
        "mean_shap": 7.409347922411805e-05,
        "std_shap": 0.0007565546889157377,
        "min_shap": -0.005436136533487344,
        "max_shap": 0.0013816011980515915
      },
      "rank": 318
    },
    {
      "feature_index": 268,
      "feature_name": "feature_268",
      "feature_code": "def feature(text: str) -> float:\n    \"Total count of punctuation characters in the text\"\n    punctuation_count = sum(1 for c in text if not c.isalnum() and not c.isspace())\n    return float(punctuation_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00042674959481354844,
        "mean_shap": -5.467148304597735e-05,
        "std_shap": 0.0005507825266156459,
        "min_shap": -0.0016047836932169646,
        "max_shap": 0.001922879764719649
      },
      "rank": 319
    },
    {
      "feature_index": 6,
      "feature_name": "feature_6",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length considering only unique words\"\n    unique_words = set(text.split())\n    if not unique_words:\n        return 0.0\n    return float(sum(len(word) for word in unique_words)) / len(unique_words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0004157975148296301,
        "mean_shap": -1.2155007906215223e-05,
        "std_shap": 0.0005576779483842717,
        "min_shap": -0.0019397410525719856,
        "max_shap": 0.0018017840603350647
      },
      "rank": 320
    },
    {
      "feature_index": 127,
      "feature_name": "feature_127",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the word 'you' in the text\"\n    return float(text.lower().count('you'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00041224414739824745,
        "mean_shap": -3.430303344636902e-05,
        "std_shap": 0.0007240051432816149,
        "min_shap": -0.0022868825680117297,
        "max_shap": 0.004228739754177618
      },
      "rank": 321
    },
    {
      "feature_index": 362,
      "feature_name": "feature_362",
      "feature_code": "def feature(text: str) -> float:\n    'Standard deviation of word lengths in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    lengths = [len(word) for word in words]\n    mean_length = statistics.mean(lengths)\n    variance = statistics.pstdev(lengths) ** 2\n    return float(variance ** 0.5)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.000410985515306616,
        "mean_shap": 6.54273531106019e-05,
        "std_shap": 0.0008018292468906725,
        "min_shap": -0.006510023756254136,
        "max_shap": 0.0011607265223930352
      },
      "rank": 322
    },
    {
      "feature_index": 316,
      "feature_name": "feature_316",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of adverbial words (ending in -ly) in the text\"\n    adverbs = len(re.findall(r'\\b\\w+ly\\b', text.lower()))\n    return float(adverbs)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00040744202763196447,
        "mean_shap": -6.836233159506387e-05,
        "std_shap": 0.0005168214350776013,
        "min_shap": -0.0013882125528209754,
        "max_shap": 0.0016905208357185536
      },
      "rank": 323
    },
    {
      "feature_index": 51,
      "feature_name": "feature_51",
      "feature_code": "def feature(text: str) -> float:\n    \"Average syllables per word in the text\"\n    def syllable_count(word):\n        word = word.lower()\n        vowels = 'aeiou'\n        return sum(1 for char in word if char in vowels)\n    \n    words = text.split()\n    if not words:\n        return 0.0\n    total_syllables = sum(syllable_count(word) for word in words)\n    return total_syllables / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0003826940163086266,
        "mean_shap": -2.6963027477951286e-05,
        "std_shap": 0.0005101065010774268,
        "min_shap": -0.0015308373749945,
        "max_shap": 0.0019461477191726599
      },
      "rank": 324
    },
    {
      "feature_index": 172,
      "feature_name": "feature_172",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of specific keywords related to feelings (happy, sad, anger, etc.)\"\n    keywords = ['happy', 'sad', 'angry', 'excited', 'bored']\n    keyword_count = sum(text.lower().count(keyword) for keyword in keywords)\n    return float(keyword_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00036843956814370155,
        "mean_shap": 9.371558027494633e-05,
        "std_shap": 0.000678963227384625,
        "min_shap": -0.005431758411557312,
        "max_shap": 0.0007104239670780402
      },
      "rank": 325
    },
    {
      "feature_index": 327,
      "feature_name": "feature_327",
      "feature_code": "def feature(text: str) -> float:\n    \"Average syllables per word in the text\"\n    def syllable_count(word):\n        word = word.lower()\n        vowels = 'aeiou'\n        return sum(1 for char in word if char in vowels)\n    \n    words = text.split()\n    if not words:\n        return 0.0\n    total_syllables = sum(syllable_count(word) for word in words)\n    return total_syllables / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0003528155839464553,
        "mean_shap": 3.8054419747860737e-06,
        "std_shap": 0.00048069794342253794,
        "min_shap": -0.0019086663082740795,
        "max_shap": 0.0013680308647050325
      },
      "rank": 326
    },
    {
      "feature_index": 194,
      "feature_name": "feature_194",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of adverbs in the text\"\n    adverb_count = len(re.findall(r'\\b\\w+ly\\b', text))\n    return float(adverb_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00034632431982516214,
        "mean_shap": -7.304274092664129e-05,
        "std_shap": 0.000500536061481327,
        "min_shap": -0.0024273097645618595,
        "max_shap": 0.0024810734742878584
      },
      "rank": 327
    },
    {
      "feature_index": 185,
      "feature_name": "feature_185",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of syllables per word in the text\"\n    def syllable_count(word):\n        return len(re.findall(r'[aeiouy]+', word.lower()))\n    \n    words = text.split()\n    if not words:\n        return 0.0\n    total_syllables = sum(syllable_count(word) for word in words)\n    return total_syllables / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0003369841628086465,
        "mean_shap": -3.253796524704842e-05,
        "std_shap": 0.00043264527631406435,
        "min_shap": -0.0010572350298131822,
        "max_shap": 0.0017794499311871111
      },
      "rank": 328
    },
    {
      "feature_index": 97,
      "feature_name": "feature_97",
      "feature_code": "def feature(text: str) -> float:\n    \"Average syllables per word in the text\"\n    words = text.split()\n    syllable_count = sum(len(re.findall(r'[aeiou]', word.lower())) for word in words)\n    if len(words) == 0:\n        return 0.0\n    return float(syllable_count) / len(words)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0003314379429631769,
        "mean_shap": -6.852590157319002e-05,
        "std_shap": 0.00045641647617399966,
        "min_shap": -0.0017003769005934203,
        "max_shap": 0.0012949574588131184
      },
      "rank": 329
    },
    {
      "feature_index": 295,
      "feature_name": "feature_295",
      "feature_code": "def feature(text: str) -> float:\n    \"Variance of word lengths in the text\"\n    word_lengths = [len(word) for word in text.split()]\n    return float(statistics.pstdev(word_lengths)) if word_lengths else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0003285681464117763,
        "mean_shap": 0.00011502088985375067,
        "std_shap": 0.00048676550515540975,
        "min_shap": -0.0030908716281953103,
        "max_shap": 0.0012399898707962493
      },
      "rank": 330
    },
    {
      "feature_index": 80,
      "feature_name": "feature_80",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of times the word 'you' appears in the text\"\n    return float(text.lower().count('you'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0003268870104593825,
        "mean_shap": -5.3539922533992994e-05,
        "std_shap": 0.0005561607520411154,
        "min_shap": -0.002208245844339292,
        "max_shap": 0.002954486872479762
      },
      "rank": 331
    },
    {
      "feature_index": 138,
      "feature_name": "feature_138",
      "feature_code": "def feature(text: str) -> float:\n    \"Standard deviation of word lengths in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    word_lengths = [len(word) for word in words]\n    return float(statistics.pstdev(word_lengths))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00032128471309823706,
        "mean_shap": 2.6831683397787647e-05,
        "std_shap": 0.0005455824157869085,
        "min_shap": -0.003537290720883492,
        "max_shap": 0.0012794054126962875
      },
      "rank": 332
    },
    {
      "feature_index": 71,
      "feature_name": "feature_71",
      "feature_code": "def feature(text: str) -> float:\n    \"Frequency of the word 'you' in the text\"\n    return float(text.lower().count('you'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00032044182139936956,
        "mean_shap": -2.116217703820597e-06,
        "std_shap": 0.0006095088589420317,
        "min_shap": -0.0016417631519795473,
        "max_shap": 0.0035004903102707706
      },
      "rank": 333
    },
    {
      "feature_index": 262,
      "feature_name": "feature_262",
      "feature_code": "def feature(text: str) -> float:\n    'Average syllables per word in the text using a simple heuristic'\n    def syllable_count(word):\n        return len(re.findall(r'[aeiouy]+', word.lower()))\n    \n    words = text.split()\n    if not words:\n        return 0.0\n    total_syllables = sum(syllable_count(word) for word in words)\n    return float(total_syllables) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00029894216331642127,
        "mean_shap": -1.6623589958236821e-06,
        "std_shap": 0.00040588991397992813,
        "min_shap": -0.0007627755347378893,
        "max_shap": 0.001585725561955868
      },
      "rank": 334
    },
    {
      "feature_index": 114,
      "feature_name": "feature_114",
      "feature_code": "def feature(text: str) -> float:\n    \"Average syllable count per word in the text\"\n    def syllable_count(word):\n        return len(re.findall(r'[aeiouy]+', word.lower()))\n    \n    words = text.split()\n    if not words:\n        return 0.0\n    return float(sum(syllable_count(word) for word in words) / len(words))\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0002904257055208091,
        "mean_shap": -3.1798949252576984e-05,
        "std_shap": 0.00037345426413060016,
        "min_shap": -0.001263008862360012,
        "max_shap": 0.000949133645233647
      },
      "rank": 335
    },
    {
      "feature_index": 230,
      "feature_name": "feature_230",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of adverbs in the text\"\n    adverbs = re.findall(r'\\b\\w+ly\\b', text)\n    return float(len(adverbs))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00028418292106927305,
        "mean_shap": -5.296700657282909e-05,
        "std_shap": 0.00037835226573228154,
        "min_shap": -0.0015609432056873846,
        "max_shap": 0.0013812290347181473
      },
      "rank": 336
    },
    {
      "feature_index": 86,
      "feature_name": "feature_86",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of syllables per word in the text\"\n    words = text.split()\n    total_syllables = sum(len(re.findall(r'[aeiouy]+', word.lower())) for word in words)\n    return total_syllables / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0002825599840582892,
        "mean_shap": -1.727638536469429e-05,
        "std_shap": 0.0003962974947237172,
        "min_shap": -0.0010370328682127858,
        "max_shap": 0.001453288972565262
      },
      "rank": 337
    },
    {
      "feature_index": 38,
      "feature_name": "feature_38",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of exclamatory sentences in the text\"\n    exclamations = len(re.findall(r'[^.!?]*![^.!?]*', text))\n    return float(exclamations)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00026692621127172663,
        "mean_shap": -0.0001041328038625898,
        "std_shap": 0.00033779112077830456,
        "min_shap": -0.0006234075612948281,
        "max_shap": 0.0016052065827910416
      },
      "rank": 338
    },
    {
      "feature_index": 189,
      "feature_name": "feature_189",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of exclamatory sentences in the text\"\n    exclamatory_count = text.count('!')\n    return float(exclamatory_count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00025270136284395,
        "mean_shap": -8.567979527858859e-05,
        "std_shap": 0.00032433373713816046,
        "min_shap": -0.0007359319079670553,
        "max_shap": 0.0018421069113582324
      },
      "rank": 339
    },
    {
      "feature_index": 66,
      "feature_name": "feature_66",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of characters per word\"\n    words = text.split()\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words)) / len(words)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0002499605951375717,
        "mean_shap": 3.33739280268682e-06,
        "std_shap": 0.0003328570800887393,
        "min_shap": -0.0012611640718912381,
        "max_shap": 0.0011010983109016482
      },
      "rank": 340
    },
    {
      "feature_index": 336,
      "feature_name": "feature_336",
      "feature_code": "def feature(text: str) -> float:\n    'Average number of syllables per word in the text'\n    def count_syllables(word):\n        return len(re.findall(r'[aeiouy]+', word.lower()))\n    words = text.split()\n    if not words:\n        return 0.0\n    syllable_counts = [count_syllables(word) for word in words]\n    return sum(syllable_counts) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00023593713521439548,
        "mean_shap": 2.0220366611651775e-05,
        "std_shap": 0.0003188435822822382,
        "min_shap": -0.000999151711124407,
        "max_shap": 0.0011213486121609104
      },
      "rank": 341
    },
    {
      "feature_index": 195,
      "feature_name": "feature_195",
      "feature_code": "def feature(text: str) -> float:\n    \"Average word length in the text\"\n    words = text.split()\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words)) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00022801297539210832,
        "mean_shap": 5.45511915423327e-07,
        "std_shap": 0.00032146494308837593,
        "min_shap": -0.0008899553832568135,
        "max_shap": 0.0016937269800571797
      },
      "rank": 342
    },
    {
      "feature_index": 98,
      "feature_name": "feature_98",
      "feature_code": "def feature(text: str) -> float:\n    \"Average sentence length measured in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    if not lengths:\n        return 0.0\n    return float(sum(lengths)) / len(lengths)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00022502071236117936,
        "mean_shap": 7.496236915767085e-06,
        "std_shap": 0.00031449632224730164,
        "min_shap": -0.0013108818839757312,
        "max_shap": 0.0007330623881043492
      },
      "rank": 343
    },
    {
      "feature_index": 46,
      "feature_name": "feature_46",
      "feature_code": "def feature(text: str) -> float:\n    'Average sentence length measured in words'\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    if not lengths:\n        return 0.0\n    return float(sum(lengths)) / len(lengths)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00021977921194207882,
        "mean_shap": 9.774543201420798e-05,
        "std_shap": 0.0002887854676093156,
        "min_shap": -0.0009649289465461899,
        "max_shap": 0.0012555871723869767
      },
      "rank": 344
    },
    {
      "feature_index": 92,
      "feature_name": "feature_92",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of characters per word\"\n    words = text.split()\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words) / len(words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00021807693945295647,
        "mean_shap": -4.111098738156492e-05,
        "std_shap": 0.0003044337728012685,
        "min_shap": -0.001128180095028047,
        "max_shap": 0.0008929039054108693
      },
      "rank": 345
    },
    {
      "feature_index": 130,
      "feature_name": "feature_130",
      "feature_code": "def feature(text: str) -> float:\n    'Average number of words per sentence'\n    sentences = re.split(r'[.!?]+', text)\n    word_counts = [len(s.split()) for s in sentences if s.split()]\n    if not word_counts:\n        return 0.0\n    return float(sum(word_counts)) / len(word_counts)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0002155736630800954,
        "mean_shap": 1.1495480786626878e-05,
        "std_shap": 0.00028884158880436325,
        "min_shap": -0.0012179766057077526,
        "max_shap": 0.0007695584676126818
      },
      "rank": 346
    },
    {
      "feature_index": 69,
      "feature_name": "feature_69",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of exclamation marks in the text\"\n    return float(text.count('!'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00020967298797232742,
        "mean_shap": -0.00012234707810524853,
        "std_shap": 0.00024785622881305186,
        "min_shap": -0.001064443546928689,
        "max_shap": 0.0016497344695711063
      },
      "rank": 347
    },
    {
      "feature_index": 293,
      "feature_name": "feature_293",
      "feature_code": "def feature(text: str) -> float:\n    'Average length of words in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words) / len(words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0001935883542706408,
        "mean_shap": -7.928761069448434e-06,
        "std_shap": 0.00027227153984068055,
        "min_shap": -0.001000401615694077,
        "max_shap": 0.001022870695431577
      },
      "rank": 348
    },
    {
      "feature_index": 192,
      "feature_name": "feature_192",
      "feature_code": "def feature(text: str) -> float:\n    'Average character length of words in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    return sum(len(word) for word in words) / len(words)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0001883249468496399,
        "mean_shap": -3.051841302927904e-05,
        "std_shap": 0.00025616939582472797,
        "min_shap": -0.0010872317639641024,
        "max_shap": 0.0008962717962284389
      },
      "rank": 349
    },
    {
      "feature_index": 47,
      "feature_name": "feature_47",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of questions in the text\"\n    question_count = text.count('?')\n    return float(question_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0001812308468754892,
        "mean_shap": 1.554696652781714e-05,
        "std_shap": 0.0002812930898124343,
        "min_shap": -0.0020546946814751594,
        "max_shap": 0.0011112158365225921
      },
      "rank": 350
    },
    {
      "feature_index": 324,
      "feature_name": "feature_324",
      "feature_code": "def feature(text: str) -> float:\n    \"Average character length of words in the text\"\n    words = text.split()\n    return float(sum(len(word) for word in words)) / len(words) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0001711941336863775,
        "mean_shap": 5.6508528620628866e-05,
        "std_shap": 0.0002221221464658537,
        "min_shap": -0.0005583312416868807,
        "max_shap": 0.0008320623360861255
      },
      "rank": 351
    },
    {
      "feature_index": 330,
      "feature_name": "feature_330",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of adjectives in the text\"\n    adjectives = set(['good', 'bad', 'happy', 'sad', 'nice', 'angry', 'big', 'small', 'beautiful', 'ugly', 'quick', 'slow'])  # Sample adjectives\n    words = text.lower().split()\n    adjective_count = sum(1 for word in words if word in adjectives)\n    return float(adjective_count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0001666160289151569,
        "mean_shap": -2.695279861015281e-05,
        "std_shap": 0.0002309710588646388,
        "min_shap": -0.0010622749570394284,
        "max_shap": 0.0008915442455246111
      },
      "rank": 352
    },
    {
      "feature_index": 184,
      "feature_name": "feature_184",
      "feature_code": "def feature(text: str) -> float:\n    \"Average sentence length in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.strip()]\n    return float(statistics.mean(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00016642641741675717,
        "mean_shap": 3.4987108731849454e-06,
        "std_shap": 0.00022275119555631141,
        "min_shap": -0.0009634261532490911,
        "max_shap": 0.0007091168951379847
      },
      "rank": 353
    },
    {
      "feature_index": 129,
      "feature_name": "feature_129",
      "feature_code": "def feature(text: str) -> float:\n    \"Average sentence length in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    return float(sum(lengths) / len(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00016272675278986183,
        "mean_shap": 1.0222155019144102e-05,
        "std_shap": 0.0002326967311422393,
        "min_shap": -0.0012038532630201152,
        "max_shap": 0.0008463028219664258
      },
      "rank": 354
    },
    {
      "feature_index": 48,
      "feature_name": "feature_48",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of explicit question marks in the text\"\n    return float(text.count('?'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00015915736503410152,
        "mean_shap": 2.0345566044834414e-05,
        "std_shap": 0.00024027850762692814,
        "min_shap": -0.00100290030862057,
        "max_shap": 0.0012511732698897641
      },
      "rank": 355
    },
    {
      "feature_index": 366,
      "feature_name": "feature_366",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of questions in the text\"\n    questions = text.count('?')\n    return float(questions)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00015506447662368085,
        "mean_shap": 2.1109687450943997e-05,
        "std_shap": 0.00022568211173840642,
        "min_shap": -0.000773084324261318,
        "max_shap": 0.0013511426609295178
      },
      "rank": 356
    },
    {
      "feature_index": 191,
      "feature_name": "feature_191",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of phrases ending with question marks\"\n    return float(text.count('?'))\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0001543846878544332,
        "mean_shap": 9.911295549503437e-06,
        "std_shap": 0.00025798233774806305,
        "min_shap": -0.0012826524740427736,
        "max_shap": 0.0008770543668886238
      },
      "rank": 357
    },
    {
      "feature_index": 235,
      "feature_name": "feature_235",
      "feature_code": "def feature(text: str) -> float:\n    'Average number of characters per word in the text'\n    words = text.split()\n    if not words:\n        return 0.0\n    return float(sum(len(word) for word in words) / len(words))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0001508376299605044,
        "mean_shap": 5.116114919363358e-07,
        "std_shap": 0.0002133101375029703,
        "min_shap": -0.0007066798252722559,
        "max_shap": 0.0007175186205396779
      },
      "rank": 358
    },
    {
      "feature_index": 314,
      "feature_name": "feature_314",
      "feature_code": "def feature(text: str) -> float:\n    'Sentence structure complexity measured by average sentence length'\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    return float(sum(lengths)) / len(lengths) if lengths else 0.0\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00014880119261014973,
        "mean_shap": -4.6010440009178033e-07,
        "std_shap": 0.0002165290172398393,
        "min_shap": -0.0007310315014792977,
        "max_shap": 0.0008265527607533998
      },
      "rank": 359
    },
    {
      "feature_index": 342,
      "feature_name": "feature_342",
      "feature_code": "def feature(text: str) -> float:\n    \"Average sentence length in words\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.split()]\n    return float(statistics.mean(lengths)) if lengths else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00014221248374059246,
        "mean_shap": 9.416502410039404e-06,
        "std_shap": 0.00018720686438075259,
        "min_shap": -0.0005391486340365376,
        "max_shap": 0.0008795678486219666
      },
      "rank": 360
    },
    {
      "feature_index": 275,
      "feature_name": "feature_275",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of adjectives in the text\"\n    adjectives = set(['good', 'bad', 'happy', 'sad', 'nice', 'angry', 'big', 'small', 'beautiful', 'ugly', 'quick', 'slow'])  # Sample adjectives\n    words = text.lower().split()\n    adjective_count = sum(1 for word in words if word in adjectives)\n    return float(adjective_count)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00014024705053578118,
        "mean_shap": 1.7074427175928114e-05,
        "std_shap": 0.0002044131801126748,
        "min_shap": -0.0007521717941948667,
        "max_shap": 0.000768444912418732
      },
      "rank": 361
    },
    {
      "feature_index": 88,
      "feature_name": "feature_88",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of words per sentence\"\n    sentences = re.split(r'[.!?]+', text)\n    lengths = [len(s.split()) for s in sentences if s.strip()]\n    if not lengths:\n        return 0.0\n    return float(sum(lengths)) / len(lengths)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00013834384911601494,
        "mean_shap": 2.3298950371455156e-06,
        "std_shap": 0.00019719192884601387,
        "min_shap": -0.0008515753410094118,
        "max_shap": 0.0006702742072322816
      },
      "rank": 362
    },
    {
      "feature_index": 167,
      "feature_name": "feature_167",
      "feature_code": "def feature(text: str) -> float:\n    \"Average number of words per sentence\"\n    sentences = re.split(r'[.!?]+', text)\n    word_counts = [len(s.split()) for s in sentences if s.strip()]\n    return float(statistics.mean(word_counts)) if word_counts else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00013782226663030988,
        "mean_shap": 4.6515253298538656e-05,
        "std_shap": 0.00019153507167672562,
        "min_shap": -0.000715772045510163,
        "max_shap": 0.0007029801687131414
      },
      "rank": 363
    },
    {
      "feature_index": 68,
      "feature_name": "feature_68",
      "feature_code": "def feature(text: str) -> float:\n    'Count of questions in the text'\n    question_count = text.count('?')\n    return float(question_count)\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00013535496782784463,
        "mean_shap": 2.6775546828424247e-05,
        "std_shap": 0.00022653464301972104,
        "min_shap": -0.0012988071540665745,
        "max_shap": 0.0014053238714476172
      },
      "rank": 364
    },
    {
      "feature_index": 206,
      "feature_name": "feature_206",
      "feature_code": "def feature(text: str) -> float:\n    \"Average character length of words in the text\"\n    words = text.split()\n    return float(sum(len(word) for word in words) / len(words)) if words else 0.0\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0001308007590462518,
        "mean_shap": -3.8594575975799184e-05,
        "std_shap": 0.00018113046937850129,
        "min_shap": -0.0006308031908869023,
        "max_shap": 0.0005164320356298964
      },
      "rank": 365
    },
    {
      "feature_index": 277,
      "feature_name": "feature_277",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of questions in the text\"\n    return float(text.count('?'))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 0.00011822818012670405,
        "mean_shap": -2.4029806598333216e-05,
        "std_shap": 0.00018063304211377043,
        "min_shap": -0.0009565979383221869,
        "max_shap": 0.0005314850308408203
      },
      "rank": 366
    },
    {
      "feature_index": 317,
      "feature_name": "feature_317",
      "feature_code": "def feature(text: str) -> float:\n    \"Count of transition phrases (e.g., 'for example', 'however', 'on the other hand')\"\n    transitions = re.findall(r'\\b(for example|however|on the other hand)\\b', text, re.IGNORECASE)\n    return float(len(transitions))\n\n",
      "shap_statistics": {
        "mean_abs_shap": 7.222399730664305e-05,
        "mean_shap": 1.089138521679068e-05,
        "std_shap": 0.00013087390932160076,
        "min_shap": -0.000571762812292553,
        "max_shap": 0.0004873390674383258
      },
      "rank": 367
    },
    {
      "feature_index": 151,
      "feature_name": "feature_151",
      "feature_code": "def feature(text: str) -> float:\n    \"Average length of longest consecutive repeated word\"\n    words = text.split()\n    max_length = 0\n    current_length = 1\n    for i in range(1, len(words)):\n        if words[i] == words[i-1]:\n            current_length += 1\n        else:\n            max_length = max(max_length, current_length)\n            current_length = 1\n    max_length = max(max_length, current_length)\n    return float(max_length)\n",
      "shap_statistics": {
        "mean_abs_shap": 0.0,
        "mean_shap": 0.0,
        "std_shap": 0.0,
        "min_shap": 0.0,
        "max_shap": 0.0
      },
      "rank": 368
    }
  ],
  "shap_metadata": {
    "explainer_type": "TreeExplainer",
    "num_features": 368
  }
}